{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-dataframe-per-batch\" data-toc-modified-id=\"Create-dataframe-per-batch-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Create dataframe per batch</a></span></li></ul></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-0.05k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-0.05k-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 0.05k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-0.1k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-0.1k-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 0.1k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-0.5k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-0.5k-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 0.5k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-2k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-2k-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 2k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-4k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-4k-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 4k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-8k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-8k-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 8k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-16k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-16k-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 16k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-20k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-20k-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 20k</a></span></li><li><span><a href=\"#Visualize-results-for-all-reports-of-the-batches\" data-toc-modified-id=\"Visualize-results-for-all-reports-of-the-batches-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Visualize results for all reports of the batches</a></span></li><li><span><a href=\"#Error-analysis\" data-toc-modified-id=\"Error-analysis-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Error analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Histograms-of-the-batches-for-job_duration\" data-toc-modified-id=\"Histograms-of-the-batches-for-job_duration-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Histograms of the batches for job_duration</a></span></li><li><span><a href=\"#Boxplot-of-the-job_duration-batches\" data-toc-modified-id=\"Boxplot-of-the-job_duration-batches-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Boxplot of the job_duration batches</a></span></li><li><span><a href=\"#Boxplot-of-the-elapsed-batches\" data-toc-modified-id=\"Boxplot-of-the-elapsed-batches-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>Boxplot of the elapsed batches</a></span></li><li><span><a href=\"#Boxplot-of-the-rate-batches\" data-toc-modified-id=\"Boxplot-of-the-rate-batches-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;</span>Boxplot of the rate batches</a></span></li><li><span><a href=\"#Boxplot-of-the-utime-batches\" data-toc-modified-id=\"Boxplot-of-the-utime-batches-11.5\"><span class=\"toc-item-num\">11.5&nbsp;&nbsp;</span>Boxplot of the utime batches</a></span></li><li><span><a href=\"#Boxplot-of-the-stime-batches\" data-toc-modified-id=\"Boxplot-of-the-stime-batches-11.6\"><span class=\"toc-item-num\">11.6&nbsp;&nbsp;</span>Boxplot of the stime batches</a></span></li><li><span><a href=\"#Boxplot-of-the-nvcsw-batches\" data-toc-modified-id=\"Boxplot-of-the-nvcsw-batches-11.7\"><span class=\"toc-item-num\">11.7&nbsp;&nbsp;</span>Boxplot of the nvcsw batches</a></span></li><li><span><a href=\"#Boxplot-of-the-nivcsw-batches\" data-toc-modified-id=\"Boxplot-of-the-nivcsw-batches-11.8\"><span class=\"toc-item-num\">11.8&nbsp;&nbsp;</span>Boxplot of the nivcsw batches</a></span></li></ul></li><li><span><a href=\"#Interpolations\" data-toc-modified-id=\"Interpolations-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Interpolations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-Deviation-for-job_duration-and-elapsed_time\" data-toc-modified-id=\"Standard-Deviation-for-job_duration-and-elapsed_time-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Standard Deviation for <code>job_duration</code> and <code>elapsed_time</code></a></span></li><li><span><a href=\"#Box-Plots-interpolated-for-job_duration\" data-toc-modified-id=\"Box-Plots-interpolated-for-job_duration-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Box Plots interpolated for <code>job_duration</code></a></span></li><li><span><a href=\"#Box-Plots-interpolated-for-elapsed_time\" data-toc-modified-id=\"Box-Plots-interpolated-for-elapsed_time-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>Box Plots interpolated for <code>elapsed_time</code></a></span></li></ul></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Correlations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correlation-between-ru_utime-and-ru_nivcsw\" data-toc-modified-id=\"Correlation-between-ru_utime-and-ru_nivcsw-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>Correlation between <code>ru_utime</code> and <code>ru_nivcsw</code></a></span></li></ul></li><li><span><a href=\"#Inspection-Time-analysis\" data-toc-modified-id=\"Inspection-Time-analysis-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Inspection Time analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inspection-Builds-Time\" data-toc-modified-id=\"Inspection-Builds-Time-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>Inspection Builds Time</a></span></li><li><span><a href=\"#Inspection-Jobs-Time\" data-toc-modified-id=\"Inspection-Jobs-Time-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>Inspection Jobs Time</a></span></li><li><span><a href=\"#Inspection-builds-+-Jobs-Time\" data-toc-modified-id=\"Inspection-builds-+-Jobs-Time-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Inspection builds + Jobs Time</a></span></li></ul></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Conclusions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Statistics\" data-toc-modified-id=\"Statistics-15.1\"><span class=\"toc-item-num\">15.1&nbsp;&nbsp;</span>Statistics</a></span></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-15.2\"><span class=\"toc-item-num\">15.2&nbsp;&nbsp;</span>Correlations</a></span></li><li><span><a href=\"#Time\" data-toc-modified-id=\"Time-15.3\"><span class=\"toc-item-num\">15.3&nbsp;&nbsp;</span>Time</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to get a notion about error rate of inspection jobs which are run on Amun API, using the following inputs:\n",
    "\n",
    "- TensorFlow 1.13 from pypi\n",
    "- fedora base image\n",
    "- matmul (tensorflow, matrix size 512, `repetitions` , float32)\n",
    "- 300 inspections\n",
    "- CPU only\n",
    "\n",
    "\n",
    "We want to understand how the error behave for different period of time/`number of repetitions` requested for an inspection. We want to understand if we can eliminate noise inside the environment. We want to find out if we can \"configure\" the error rate in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:34.893385Z",
     "start_time": "2019-08-19T11:23:34.889533Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import functools\n",
    "import re\n",
    "\n",
    "import textwrap\n",
    "import typing\n",
    "\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from typing import Callable, Iterable\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:38.284663Z",
     "start_time": "2019-08-19T11:23:35.247360Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import thoth.lab.underscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from thoth.storages import InspectionResultsStore\n",
    "from thoth.lab import inspection\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 800)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:38.416139Z",
     "start_time": "2019-08-19T11:23:38.286062Z"
    }
   },
   "outputs": [],
   "source": [
    "import cufflinks as cf\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "\n",
    "from plotly import graph_objs as go\n",
    "from plotly import figure_factory as ff\n",
    "from plotly import tools\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "# plotly\n",
    "init_notebook_mode()\n",
    "\n",
    "# cufflinks\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:44:34.420551Z",
     "start_time": "2019-08-19T14:44:34.347663Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_analysis_plot(batch_identifier: str):\n",
    "    \"Create analysis plots per batch\"\n",
    "    fig = inspection.create_duration_box(df_duration_total[batch_identifier], [\"build_duration\", \"job_duration\"])\n",
    "\n",
    "    py.iplot(fig)\n",
    "\n",
    "    fig = inspection.create_duration_scatter(\n",
    "        df_duration_total[batch_identifier], \"job_duration\", title=\"InspectionRun job duration\"\n",
    "    )\n",
    "\n",
    "    py.iplot(fig)\n",
    "\n",
    "    fig = inspection.create_duration_scatter(\n",
    "        df_duration_total[batch_identifier], \"build_duration\", title=\"InspectionRun build duration\"\n",
    "    )\n",
    "\n",
    "    py.iplot(fig)\n",
    "\n",
    "    fig = inspection.create_duration_histogram(df_duration_total[batch_identifier], [\"job_duration\"])\n",
    "\n",
    "    py.iplot(fig)\n",
    "\n",
    "    \n",
    "def create_box_plot(data: pd.DataFrame,\n",
    "               columns: Union[str, List[str]] = None,\n",
    "               title_box: str = \"Box plot\",\n",
    "               y_label: str = \"Variable [Measurement Unit]\",\n",
    "               static: str = False):\n",
    "    \"\"\"Create duration Box plot.\"\"\"\n",
    "    columns = columns if columns is not None else data[columns].columns     \n",
    "        \n",
    "    figure = data[columns].iplot(\n",
    "        kind=\"box\", title=title_box, yTitle=y_label, asFigure=True\n",
    "    )\n",
    "\n",
    "    return figure\n",
    "\n",
    "\n",
    "def create_batches_filter(parameter: str, inspection_batch_names: list) -> List:\n",
    "    \"\"\"Create batch filter for plots.\"\"\"\n",
    "    batches_list = []\n",
    "    for identifier in inspection_batch_names:\n",
    "        batches_list.append(parameter + \"_\" + str(identifier.split(\"-\")[0]))\n",
    "        \n",
    "    return batches_list\n",
    "\n",
    "\n",
    "def create_scatter_and_correlation(data: pd.DataFrame,\n",
    "                                  columns: Union[str, List[str]] = None,\n",
    "                                  title_scatter: str = \"Scatter plot\"):\n",
    "    \"\"\"Create Scatter plot and evaluate correlation coefficients.\"\"\"\n",
    "    columns = columns if columns is not None else data[columns].columns\n",
    "\n",
    "    figure = data[columns].iplot(\n",
    "        kind=\"scatter\",\n",
    "        x=columns[0],\n",
    "        y=columns[1],\n",
    "        title=title_scatter,\n",
    "        xTitle=columns[0],\n",
    "        yTitle=columns[1],\n",
    "        mode='markers',\n",
    "        asFigure=True\n",
    "    )\n",
    "\n",
    "    corr_pearson = data[columns].corr(\"pearson\")\n",
    "    print()\n",
    "    print(\"Pearson correlation results:\")\n",
    "    print(corr_pearson)\n",
    "\n",
    "    corr_spearman = data[columns].corr(\"spearman\")\n",
    "    print()\n",
    "    print(\"Spearman correlation results:\")\n",
    "    print(corr_spearman)\n",
    "    \n",
    "    corr_kendall = data[columns].corr(\"kendall\")\n",
    "    print()\n",
    "    print(\"Kendall correlation results:\")\n",
    "    print(corr_kendall)\n",
    "    \n",
    "    return figure\n",
    "\n",
    "\n",
    "def create_scatter_plots_for_multiple_batches(data: pd.DataFrame,\n",
    "                                  columns: Union[str, List[str]] = None,\n",
    "                                  list_batches: List[str] = [], \n",
    "                                  title_scatter: str = \"Scatter plot\",\n",
    "                                  x_label: str = \" \", \n",
    "                                  y_label: str = \" \"):\n",
    "    \"\"\"Create Scatter plots for multiple batches.\"\"\"\n",
    "    columns = columns if columns is not None else data[columns].columns\n",
    "\n",
    "    figure = {\n",
    "    'data': [\n",
    "        {\n",
    "            'x': data[columns[0] + '_' + batch],\n",
    "            'y': data[columns[1] + '_' + batch],\n",
    "            'name': batch, 'mode': 'markers',\n",
    "        } for batch in list_batches\n",
    "    ],\n",
    "    'layout': {\n",
    "        'xaxis': {'title': x_label},\n",
    "        'yaxis': {'title': y_label}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return figure\n",
    "\n",
    "\n",
    "def evaluate_statistics(identifier, key_name) -> Dict:\n",
    "    \"\"\"Evaluate statistical quantities for plots\"\"\"\n",
    "    cv = df_total[identifier][key_name].std()/df_total[identifier][key_name].mean()*100\n",
    "    std_error = df_total[identifier][key_name].std()/np.sqrt(df_total[identifier][key_name].shape[0])\n",
    "    std = df_total[identifier][key_name].std()\n",
    "    median = df_total[identifier][key_name].median()\n",
    "    q = df_total[identifier][key_name].quantile([.25, .75])\n",
    "    q1 =  q[0.25]\n",
    "    q3 =  q[0.75]\n",
    "    IQR = q3 - q1\n",
    "    maxr = df_total[identifier][key_name].max()\n",
    "    minr = df_total[identifier][key_name].min()\n",
    "\n",
    "    return {\"cv\": cv,\n",
    "            \"std_error\": std_error,\n",
    "            \"std\": std,\n",
    "            \"median\": median,\n",
    "            \"q1\":q1,\n",
    "            \"q3\": q3,\n",
    "            \"iqr\": IQR,\n",
    "            \"max\": maxr,\n",
    "            \"min\": minr}\n",
    "\n",
    "\n",
    "def evaluate_statistics_per_parameter(key: str) -> Dict:\n",
    "    \"\"\"Aggregate results of statistics per parameter\"\"\"\n",
    "    quantities = {}\n",
    "    for identifier in identifier_inspection:\n",
    "        quantities[identifier] = evaluate_statistics(\n",
    "            identifier=identifier,\n",
    "            key_name=key)\n",
    "        \n",
    "    results = {}\n",
    "    \n",
    "    for quantity in quantities[identifier].keys():\n",
    "        results[quantity] = [values[quantity] for values in quantities.values()]\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_batches_statistics_interpolated_single_parameter(parameter_selected: str,\n",
    "                                                          colour_list: List,\n",
    "                                                          quantities: List,\n",
    "                                                          title_ylabel: str):\n",
    "    \"\"\"Plot interpolated statistics for different batches for a specific parameter\"\"\"\n",
    "    if len(colour_list) != len(quantities):\n",
    "        logger.exception(f\"List of statistical quantities and List of colours need to have the same length!\")\n",
    "    i = 0\n",
    "    parameter_results = dftotal_statistics[parameter_selected]\n",
    "    for quantity in quantities:\n",
    "        plt.plot(identifier_inspection, parameter_results[quantity], f'{colour[i]}o-', label=f'{quantity}')\n",
    "        i += 1\n",
    "    plt.xlabel('Batch Identifier')\n",
    "    plt.title(f'Statistics plot for {parameter_selected} of different batch')\n",
    "    plt.tick_params(axis='x', rotation=45)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_batches_statistics_interpolated_different_parameters(parameters_selected: List,\n",
    "                                                              colour_list: List,\n",
    "                                                              quantity: str,\n",
    "                                                              title_ylabel: str):\n",
    "    \"\"\"Plot interpolated statistics for different batches for different parameters\"\"\"\n",
    "    if len(colour_list) != len(parameters_selected):\n",
    "        logger.exception(f\"List of parameters and List of colours need to have the same length!\")\n",
    "    i = 0\n",
    "    for parameter in parameters_selected:\n",
    "        parameter_results = dftotal_statistics[parameter]\n",
    "        plt.plot(identifier_inspection, parameter_results[quantity], f'{colour[i]}o-', label=f'{parameter}')\n",
    "        i += 1\n",
    "    plt.xlabel('Batch Identifier')\n",
    "    plt.ylabel(title_ylabel)\n",
    "    plt.title(f'Statistics plot for {quantity} of different batch for different parameters')\n",
    "    plt.tick_params(axis='x', rotation=45)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def show_categories(inspection_df: pd.DataFrame):\n",
    "    \"\"\"List categories in the given DataFrame.\"\"\"\n",
    "    index = inspection_df.index.droplevel(-1).unique()\n",
    "\n",
    "    results_categories = {}\n",
    "    for n, idx in enumerate(index.values):\n",
    "        print(\"\\nClass {}/{}\".format(n + 1, len(index)))\n",
    "        \n",
    "        class_results = {}\n",
    "        if len(index.names) > 1:\n",
    "            for name, ind in zip(index.names, idx):\n",
    "                print(f\"{name} :\", ind)\n",
    "                class_results[name] = ind\n",
    "        else:\n",
    "            print(f\"{index.names[0]} :\", idx)\n",
    "            class_results[index.names[0]] = idx\n",
    "        results_categories[n + 1] = class_results\n",
    "\n",
    "        frame = inspection_df.loc[idx]\n",
    "        print(\"Number of rows (jobs) is:\", frame.shape[0])\n",
    "        \n",
    "    return results_categories\n",
    "\n",
    "\n",
    "def create_report(df: pd.DataFrame):\n",
    "    \"\"\"Create report describing the batch of inspection jobs for the different features.\"\"\"\n",
    "    report_results = {}\n",
    "    print()\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"Hardware (Platform + Processor + ncpus)\")\n",
    "    print(\"=========================================================================\")\n",
    "    \n",
    "    # Main Class\n",
    "#     hardware = inspection.query_inspection_dataframe(df, groupby=[\"platform\", \"job_log__hwinfo__cpu__is\", \"job_log__hwinfo__cpu__has\", \"ncpus\"], exclude=\"node\")\n",
    "    report_results[\"hardware\"] = {}\n",
    "\n",
    "    # Sub classes\n",
    "    platform = inspection.query_inspection_dataframe(df, groupby=[\"platform\"], exclude=\"node\")\n",
    "    processor = inspection.query_inspection_dataframe(df, groupby=[\"job_log__hwinfo__cpu__is\", \"job_log__hwinfo__cpu__has\"], exclude=\"node\")\n",
    "    ncpus = inspection.query_inspection_dataframe(df, groupby=[\"ncpus\"], exclude=\"node\")\n",
    "    print()\n",
    "    print(\"Platform\")\n",
    "    report_results[\"hardware\"][\"platform\"] = show_categories(platform)\n",
    "    print()\n",
    "    print(\"Processor\")\n",
    "    report_results[\"hardware\"][\"processor\"] = show_categories(processor)\n",
    "    print()\n",
    "    print(\"Number CPUs\")\n",
    "    report_results[\"hardware\"][\"ncpus\"] = show_categories(ncpus)\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"Software stack (python packages installed + index)\")\n",
    "    print(\"=========================================================================\")\n",
    "    \n",
    "#     software_stack = inspection.query_inspection_dataframe(df, groupby=[\"specification__python__requirements_locked__default\", \"index\"], exclude=\"node\")\n",
    "    report_results[\"software_stack\"] = {}\n",
    "    \n",
    "    # Sub classes\n",
    "    index = inspection.query_inspection_dataframe(df, groupby=[\"index\"], exclude=\"node\")\n",
    "    requirements_locked = inspection.query_inspection_dataframe(df, groupby=[\"specification__python__requirements_locked__default\"], exclude=\"node\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Index\")\n",
    "    report_results[\"software_stack\"][\"index\"] = show_categories(index)\n",
    "    print()\n",
    "    print(\"Requirements_locked\")\n",
    "    report_results[\"software_stack\"][\"requirements_locked\"] = show_categories(requirements_locked)\n",
    "\n",
    "    \n",
    "    print()\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"Base image\")\n",
    "    print(\"=========================================================================\")\n",
    "    \n",
    "    base_image = inspection.query_inspection_dataframe(df, groupby=\"base\", exclude=\"node\")\n",
    "    report_results[\"base_image\"] = show_categories(base_image)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"PI (script + sha256 + parameters)\")\n",
    "    print(\"=========================================================================\")\n",
    "    \n",
    "#     script = inspection.query_inspection_dataframe(df, groupby=[\"script\", \"script_sha256\", \"@parameters\"], exclude=\"node\")\n",
    "    report_results[\"pi\"] = {}\n",
    "    \n",
    "    # Sub classes\n",
    "    script = inspection.query_inspection_dataframe(df, groupby=[\"script\", \"script_sha256\"], exclude=\"node\")\n",
    "    parameters = inspection.query_inspection_dataframe(df, groupby=[\"name\", \"@parameters\"], exclude=\"node\")\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print(\"Script\")\n",
    "    report_results[\"pi\"][\"script\"] = show_categories(script)\n",
    "    print()\n",
    "    print(\"PI parameters\")\n",
    "    report_results[\"pi\"][\"parameters\"] = show_categories(parameters)\n",
    "    \n",
    "    print()\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"Build request (hardware + memory) and Run request (hardware + memory)\")\n",
    "    print(\"=========================================================================\")\n",
    "    \n",
    "#     requests = inspection.query_inspection_dataframe(df, groupby=\"requests\", exclude=\"node\")\n",
    "    report_results[\"requests\"] = {}\n",
    "    \n",
    "    # Sub classes\n",
    "    build_requests = inspection.query_inspection_dataframe(df, groupby=[\"build__requests\"], exclude=\"node\")\n",
    "    run_requests = inspection.query_inspection_dataframe(df, groupby=[\"run__requests\"], exclude=\"node\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Build requests\")\n",
    "    report_results[\"requests\"][\"build\"] = show_categories(build_requests)\n",
    "    print()\n",
    "    print(\"Run requests\")\n",
    "    report_results[\"requests\"][\"run\"] = show_categories(run_requests)\n",
    "    \n",
    "    print()\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"Failure build (exit_code) and Failure run (exit_code)\")\n",
    "    print(\"=========================================================================\")\n",
    "    \n",
    "#     exit_codes = inspection.query_inspection_dataframe(df, groupby=\"exit_code\", exclude=\"node\")\n",
    "    report_results[\"exit_codes\"] = {}\n",
    "    \n",
    "    # Sub classes\n",
    "    build__exit_code = inspection.query_inspection_dataframe(df, groupby=[\"build__exit_code\"], exclude=\"node\")\n",
    "    job_exit_code = inspection.query_inspection_dataframe(df, groupby=[\"job__exit_code\", \"job_log__exit_code\"], exclude=\"node\")\n",
    "\n",
    "    print()\n",
    "    print(\"Build exit_code\")\n",
    "    report_results[\"exit_codes\"][\"build\"] = show_categories(build__exit_code)\n",
    "    print()\n",
    "    print(\"Job exit_code\")\n",
    "    report_results[\"exit_codes\"][\"run\"] = show_categories(job_exit_code)\n",
    "    \n",
    "    return report_results\n",
    "\n",
    "\n",
    "def extract_features(reports: dict) -> dict:\n",
    "    \"\"\"Extract fetaures and sub-features provided in each report\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    for batch, batch_results in reports.items():\n",
    "        for feature, feature_results in batch_results.items():\n",
    "            \n",
    "            if feature not in features:\n",
    "                features[feature] = []\n",
    "                \n",
    "            for sub_feature, sub_feature_results in feature_results.items():\n",
    "                \n",
    "                if type(sub_feature) == str and sub_feature not in features[feature]:\n",
    "                    features[feature].append(sub_feature)\n",
    "                    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_results_per_feature(reports: dict) -> dict:\n",
    "    \"\"\"Extract results for each batch for all features\"\"\"\n",
    "    features = extract_features(reports)\n",
    "    results_per_feature_per_batch = {}\n",
    "    \n",
    "    for feature, sub_features in features.items():\n",
    "        for batch in tot_reports.keys():\n",
    "            \n",
    "            if sub_features:\n",
    "                if feature not in results_per_feature_per_batch.keys():\n",
    "                    results_per_feature_per_batch[feature] = {}\n",
    "                    \n",
    "                for sub_feature in sub_features:\n",
    "                    \n",
    "                    if sub_feature not in results_per_feature_per_batch[feature].keys():\n",
    "                        results_per_feature_per_batch[feature][sub_feature] = []\n",
    "                        \n",
    "                    for k, v in tot_reports[batch][feature][sub_feature].items():\n",
    "                        results_per_feature_per_batch[feature][sub_feature].append(tot_reports[batch][feature][sub_feature][k])\n",
    "            else:\n",
    "                \n",
    "                if feature not in results_per_feature_per_batch.keys():\n",
    "                    results_per_feature_per_batch[feature] = []\n",
    "                    \n",
    "                for k, v in tot_reports[batch][feature].items():\n",
    "                    results_per_feature_per_batch[feature].append(tot_reports[batch][feature][k])\n",
    "                    \n",
    "    return results_per_feature_per_batch\n",
    "\n",
    "\n",
    "def create_feature_summary(results_features: dict, debug: bool = False) -> dict:\n",
    "    \"\"\"Create summary of number of combinations per features\"\"\"\n",
    "    features_summary = {}\n",
    "    debug_summary = {}\n",
    "    for feature, feature_results in results_features.items():\n",
    "        debug_summary[feature] = {}\n",
    "        \n",
    "        if type(feature_results) != list:\n",
    "            features_summary[feature] = {}\n",
    "            \n",
    "            for sub_feature, sub_feature_results in feature_results.items():\n",
    "                debug_summary[feature][sub_feature] = {}\n",
    "                keys = [key for key in sub_feature_results[0].keys()]\n",
    "                key_counts = {}\n",
    "                \n",
    "                for key in keys:\n",
    "                    \n",
    "                    key_counts[key] = len(set([k[key] for k in results_features[feature][sub_feature]]))\n",
    "                    \n",
    "                    if key_counts[key] != 1:\n",
    "                        debug_summary[feature][sub_feature][key] = set([k[key] for k in results_features[feature][sub_feature]])\n",
    "                        \n",
    "                features_summary[feature][sub_feature] = key_counts\n",
    "        else:\n",
    "            keys = [key for key in feature_results[0].keys()]\n",
    "            key_counts = {}\n",
    "            \n",
    "            for key in keys:\n",
    "                key_counts[key] = len(set([k[key] for k in results_features[feature]]))\n",
    "                \n",
    "                if key_counts[key] != 1:\n",
    "                    debug_summary[feature][key] = set([k[key] for k in results_features[feature]])\n",
    "                    \n",
    "            features_summary[feature] = key_counts\n",
    "    if debug:\n",
    "        return features_summary, debug_summary\n",
    "    \n",
    "    return features_summary\n",
    "\n",
    "def identify_differences_inspection_results(summary_debug: dict):\n",
    "    \"\"\"Function to identify differences in batches\"\"\"\n",
    "    for feature, feature_results in summary_debug.items():\n",
    "        print(\"=====================================================================================\")\n",
    "        print(feature)\n",
    "        print(\"=====================================================================================\")\n",
    "        if summary_debug[feature]:\n",
    "            for sub_feature, sub_feature_results in feature_results.items():\n",
    "                if sub_feature_results:\n",
    "                    print(\"---------------------------------------\")\n",
    "                    print(sub_feature)\n",
    "                    print(\"---------------------------------------\")\n",
    "                    for key in sub_feature_results.keys():\n",
    "                        for value in sub_feature_results[key]:\n",
    "                            print()\n",
    "                            print(f\"{key}: {value}\")\n",
    "                            for batch, batch_results in tot_reports.items():\n",
    "                                for b, r in batch_results[feature][sub_feature].items():\n",
    "                                    if r[key] == value:\n",
    "                                        print(\"Identifier:\", batch)\n",
    "        else:\n",
    "            if feature_results:\n",
    "                for key in feature_results.keys():\n",
    "                    for value in sub_feature_results[key]:\n",
    "                        print(\"=======================================\")\n",
    "                        print()\n",
    "                        print(f\"{key}: {value}\")\n",
    "                        for batch, batch_results in tot_reports.items():\n",
    "                            for b, r in batch_results[feature].items():\n",
    "                                if r[key] == value:\n",
    "                                    print(\"Identifier:\", batch)\n",
    "\n",
    "                                    \n",
    "def visualize_summary(summary_results: dict):\n",
    "    \"\"\"Visualize summary of results (if there are any differences)\"\"\"\n",
    "    for feature, feature_results in summary.items():\n",
    "        print(\"=====================================================================================\")\n",
    "        print(feature)\n",
    "        print(\"=====================================================================================\")\n",
    "        if len(feature_results) > 1:\n",
    "            for sub_feature, sub_feature_results in feature_results.items():\n",
    "                print(\"-------------------------------------------------------------------------------\")\n",
    "                print(sub_feature)\n",
    "                for key, count in sub_feature_results.items():\n",
    "                    if count > 1:\n",
    "                        print(f\"{key}: {count}\")\n",
    "        else:\n",
    "            for key, count in feature_results.items():\n",
    "                if count > 1:\n",
    "                    print(\"=====================================================================================\")\n",
    "                    print(feature)\n",
    "                    print(\"=====================================================================================\")\n",
    "                    print(f\"{key}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T12:54:34.955207Z",
     "start_time": "2019-08-19T12:54:34.935638Z"
    }
   },
   "outputs": [],
   "source": [
    "%env THOTH_DEPLOYMENT_NAME     thoth-core-psi-stage\n",
    "%env THOTH_CEPH_BUCKET         thoth\n",
    "%env THOTH_CEPH_BUCKET_PREFIX  data/thoth\n",
    "%env THOTH_S3_ENDPOINT_URL     https://s3.upshift.redhat.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:41.213146Z",
     "start_time": "2019-08-19T11:23:41.096235Z"
    }
   },
   "outputs": [],
   "source": [
    "inspection_store = InspectionResultsStore(region=\"eu-central-1\")\n",
    "inspection_store.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:24:31.607690Z",
     "start_time": "2019-08-19T11:23:41.922016Z"
    }
   },
   "outputs": [],
   "source": [
    "all_document_ids = inspection_store.get_document_listing()\n",
    "\n",
    "list_ids = [str(cid) for cid in all_document_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:24:31.645988Z",
     "start_time": "2019-08-19T11:24:31.609148Z"
    }
   },
   "outputs": [],
   "source": [
    "identifier_inspection = [\n",
    "    \"005k-test-new\",\n",
    "    \"01k-test-new\",\n",
    "    \"05k-test-new\",\n",
    "    \"2k-test-new\",\n",
    "    \"4k-test-new\",\n",
    "    \"8k-test-new\",\n",
    "    \"16k-test-new\",\n",
    "    \"20k-test-new\"\n",
    "]\n",
    "\n",
    "# Filter list of ids\n",
    "filtered_list_ids = {}\n",
    "\n",
    "for identifier in identifier_inspection:\n",
    "    filtered_list_ids[identifier] = []\n",
    "    \n",
    "for ids in list_ids:\n",
    "    inspection_filter = \"-\".join(ids.split(\"-\")[1:(len(ids.split(\"-\")) - 1)])\n",
    "    if inspection_filter:\n",
    "        if inspection_filter in identifier_inspection:\n",
    "            filtered_list_ids[inspection_filter].append(ids)\n",
    "print(f\"The analysis consider {sum([len(batch_n) for batch_n in filtered_list_ids.values()])} inspection runs!: {[len(batch_n) for batch_n in filtered_list_ids.values()]} respectively\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:42:37.082886Z",
     "start_time": "2019-08-19T11:24:31.647927Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspection_results = {}\n",
    "tot = sum([len(r) for r in filtered_list_ids.values()])\n",
    "n = 1\n",
    "for identifier in identifier_inspection:\n",
    "    inspection_results[identifier] = []\n",
    "\n",
    "    for ids in filtered_list_ids[identifier]:\n",
    "        document = inspection_store.retrieve_document(ids)\n",
    "        # pop build logs to save some memory (not necessary for now)\n",
    "        document[\"build_log\"] = None\n",
    "        print(f\"{n}/{tot}\")\n",
    "        inspection_results[identifier].append(document)\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:43:45.236381Z",
     "start_time": "2019-08-19T11:42:37.090449Z"
    }
   },
   "outputs": [],
   "source": [
    "df_total = {}\n",
    "\n",
    "for identifier, inspection_results_list in inspection_results.items():\n",
    "    \n",
    "    df = inspection.process_inspection_results(\n",
    "        inspection_results_list,\n",
    "        exclude=[\"build_log\", \"created\", \"inspection_id\"],\n",
    "        apply=[(\"created|started_at|finished_at\", pd.to_datetime)],\n",
    "        drop=False\n",
    "    )\n",
    "    \n",
    "    df_total[identifier] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:43:45.438703Z",
     "start_time": "2019-08-19T11:43:45.238353Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total = {}\n",
    "for identifier, dataframe in df_total.items():\n",
    "    df_duration = inspection.create_duration_dataframe(dataframe)\n",
    "    df_duration_total[identifier] = df_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:43:45.453003Z",
     "start_time": "2019-08-19T11:43:45.440185Z"
    }
   },
   "outputs": [],
   "source": [
    "for identifier, df_duration in df_duration_total.items():\n",
    "    df_total[identifier][\"job_duration\"] = df_duration[\"job_duration\"]\n",
    "    df_total[identifier][\"build_duration\"] = df_duration[\"build_duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:02:17.702470Z",
     "start_time": "2019-08-19T14:02:17.699578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect all reports and provide results\n",
    "tot_reports = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 0.05k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:53:42.659655Z",
     "start_time": "2019-08-19T11:53:41.817501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"005k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:53:51.894600Z",
     "start_time": "2019-08-19T11:53:51.846283Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"005k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:02:21.339768Z",
     "start_time": "2019-08-19T14:02:20.953423Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_reports[\"005k-test-new\"] = create_report(df_total[\"005k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 0.1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:29.133175Z",
     "start_time": "2019-08-09T09:22:28.472649Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"01k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:24:03.626310Z",
     "start_time": "2019-08-09T09:24:03.582204Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"01k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:32.213860Z",
     "start_time": "2019-08-19T14:04:31.834655Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_reports[\"01k-test-new\"] = create_report(df_total[\"01k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 0.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:33.224280Z",
     "start_time": "2019-08-09T09:22:32.980684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"05k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:24:01.480436Z",
     "start_time": "2019-08-09T09:24:01.445745Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"05k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:35.174685Z",
     "start_time": "2019-08-19T14:04:34.786212Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"05k-test-new\"] = create_report(df_total[\"05k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:35.223096Z",
     "start_time": "2019-08-09T09:22:34.987174Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"2k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:45:13.351695Z",
     "start_time": "2019-08-19T14:45:13.307507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_duration</th>\n",
       "      <th>build_duration</th>\n",
       "      <th>job_duration_mean</th>\n",
       "      <th>job_duration_upper_bound</th>\n",
       "      <th>job_duration_lower_bound</th>\n",
       "      <th>build_duration_mean</th>\n",
       "      <th>build_duration_upper_bound</th>\n",
       "      <th>build_duration_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>3.000000e+02</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.00</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.090000</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>4.009000e+01</td>\n",
       "      <td>44.638000</td>\n",
       "      <td>35.542000</td>\n",
       "      <td>6.97</td>\n",
       "      <td>36.962300</td>\n",
       "      <td>-23.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.547986</td>\n",
       "      <td>29.992347</td>\n",
       "      <td>7.117299e-15</td>\n",
       "      <td>4.547986</td>\n",
       "      <td>4.547986</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.992347</td>\n",
       "      <td>29.992347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.009000e+01</td>\n",
       "      <td>33.548000</td>\n",
       "      <td>24.452000</td>\n",
       "      <td>6.97</td>\n",
       "      <td>30.992300</td>\n",
       "      <td>-28.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.009000e+01</td>\n",
       "      <td>42.548000</td>\n",
       "      <td>33.452000</td>\n",
       "      <td>6.97</td>\n",
       "      <td>31.992300</td>\n",
       "      <td>-27.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.009000e+01</td>\n",
       "      <td>45.548000</td>\n",
       "      <td>36.452000</td>\n",
       "      <td>6.97</td>\n",
       "      <td>31.992300</td>\n",
       "      <td>-27.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.009000e+01</td>\n",
       "      <td>47.548000</td>\n",
       "      <td>38.452000</td>\n",
       "      <td>6.97</td>\n",
       "      <td>32.992300</td>\n",
       "      <td>-26.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>4.009000e+01</td>\n",
       "      <td>87.548000</td>\n",
       "      <td>78.452000</td>\n",
       "      <td>6.97</td>\n",
       "      <td>340.992300</td>\n",
       "      <td>281.007700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_duration  build_duration  job_duration_mean  \\\n",
       "count    300.000000      300.000000       3.000000e+02   \n",
       "mean      40.090000        6.970000       4.009000e+01   \n",
       "std        4.547986       29.992347       7.117299e-15   \n",
       "min       29.000000        1.000000       4.009000e+01   \n",
       "25%       38.000000        2.000000       4.009000e+01   \n",
       "50%       41.000000        2.000000       4.009000e+01   \n",
       "75%       43.000000        3.000000       4.009000e+01   \n",
       "max       83.000000      311.000000       4.009000e+01   \n",
       "\n",
       "       job_duration_upper_bound  job_duration_lower_bound  \\\n",
       "count                300.000000                300.000000   \n",
       "mean                  44.638000                 35.542000   \n",
       "std                    4.547986                  4.547986   \n",
       "min                   33.548000                 24.452000   \n",
       "25%                   42.548000                 33.452000   \n",
       "50%                   45.548000                 36.452000   \n",
       "75%                   47.548000                 38.452000   \n",
       "max                   87.548000                 78.452000   \n",
       "\n",
       "       build_duration_mean  build_duration_upper_bound  \\\n",
       "count               300.00                  300.000000   \n",
       "mean                  6.97                   36.962300   \n",
       "std                   0.00                   29.992347   \n",
       "min                   6.97                   30.992300   \n",
       "25%                   6.97                   31.992300   \n",
       "50%                   6.97                   31.992300   \n",
       "75%                   6.97                   32.992300   \n",
       "max                   6.97                  340.992300   \n",
       "\n",
       "       build_duration_lower_bound  \n",
       "count                  300.000000  \n",
       "mean                   -23.022300  \n",
       "std                     29.992347  \n",
       "min                    -28.992300  \n",
       "25%                    -27.992300  \n",
       "50%                    -27.992300  \n",
       "75%                    -26.992300  \n",
       "max                    281.007700  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duration_total[\"2k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:45:16.277626Z",
     "start_time": "2019-08-19T14:45:15.917471Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 'job_log__hwinfo__platform__architecture' dtype NOT understood. Dropped\n",
      "Column 'job_log__hwinfo__cpu__is_32bit' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_64bit' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Alpha' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Core2' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_EV4' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_EV5' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_EV56' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Itanium' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_PCA56' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power7' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power8' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power9' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_i386' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_i486' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__has_Altivec' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__has_f00f_bug' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__has_fdiv_bug' could NOT be used as index group. Dropped.\n",
      "Column 'specification__python__requirements_locked__default__absl-py__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__astor__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__gast__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__grpcio__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__h5py__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__keras-applications__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__keras-preprocessing__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__markdown__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__mock__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__numpy__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__protobuf__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__six__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__tensorboard__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__tensorflow-estimator__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__tensorflow__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__termcolor__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__werkzeug__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__wheel__hashes' dtype NOT understood. Dropped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "Hardware (Platform + Processor + ncpus)\n",
      "=========================================================================\n",
      "\n",
      "Platform\n",
      "\n",
      "Class 1/1\n",
      "job_log__hwinfo__platform__machine : x86_64\n",
      "job_log__hwinfo__platform__platform : Linux-3.10.0-957.21.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core\n",
      "job_log__hwinfo__platform__processor : x86_64\n",
      "job_log__hwinfo__platform__release : 3.10.0-957.21.2.el7.x86_64\n",
      "job_log__hwinfo__platform__version : #1 SMP Tue May 28 09:26:43 UTC 2019\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "Processor\n",
      "\n",
      "Class 1/1\n",
      "job_log__hwinfo__cpu__is_AMD : False\n",
      "job_log__hwinfo__cpu__is_AMD64 : False\n",
      "job_log__hwinfo__cpu__is_Athlon64 : False\n",
      "job_log__hwinfo__cpu__is_AthlonHX : False\n",
      "job_log__hwinfo__cpu__is_AthlonK6 : False\n",
      "job_log__hwinfo__cpu__is_AthlonK6_2 : False\n",
      "job_log__hwinfo__cpu__is_AthlonK6_3 : False\n",
      "job_log__hwinfo__cpu__is_AthlonK7 : False\n",
      "job_log__hwinfo__cpu__is_AthlonMP : False\n",
      "job_log__hwinfo__cpu__is_Celeron : False\n",
      "job_log__hwinfo__cpu__is_Hammer : False\n",
      "job_log__hwinfo__cpu__is_Intel : True\n",
      "job_log__hwinfo__cpu__is_Nocona : False\n",
      "job_log__hwinfo__cpu__is_Opteron : False\n",
      "job_log__hwinfo__cpu__is_Pentium : False\n",
      "job_log__hwinfo__cpu__is_PentiumII : False\n",
      "job_log__hwinfo__cpu__is_PentiumIII : False\n",
      "job_log__hwinfo__cpu__is_PentiumIV : False\n",
      "job_log__hwinfo__cpu__is_PentiumM : False\n",
      "job_log__hwinfo__cpu__is_PentiumMMX : False\n",
      "job_log__hwinfo__cpu__is_PentiumPro : False\n",
      "job_log__hwinfo__cpu__is_Prescott : False\n",
      "job_log__hwinfo__cpu__is_XEON : True\n",
      "job_log__hwinfo__cpu__is_Xeon : True\n",
      "job_log__hwinfo__cpu__is_i586 : False\n",
      "job_log__hwinfo__cpu__is_i686 : True\n",
      "job_log__hwinfo__cpu__is_singleCPU : False\n",
      "job_log__hwinfo__cpu__has_3dnow : False\n",
      "job_log__hwinfo__cpu__has_3dnowext : False\n",
      "job_log__hwinfo__cpu__has_mmx : True\n",
      "job_log__hwinfo__cpu__has_sse : True\n",
      "job_log__hwinfo__cpu__has_sse2 : True\n",
      "job_log__hwinfo__cpu__has_sse3 : True\n",
      "job_log__hwinfo__cpu__has_ssse3 : True\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "Number CPUs\n",
      "\n",
      "Class 1/1\n",
      "job_log__hwinfo__cpu__ncpus : 64\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "Software stack (python packages installed + index)\n",
      "=========================================================================\n",
      "\n",
      "Index\n",
      "\n",
      "Class 1/1\n",
      "specification__python__requirements__packages__tensorflow__index : pypi-org\n",
      "specification__python__requirements_locked__default__tensorflow__index : pypi-org\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "Requirements_locked\n",
      "\n",
      "Class 1/1\n",
      "specification__python__requirements_locked__default__absl-py__version : ==0.7.1\n",
      "specification__python__requirements_locked__default__astor__version : ==0.8.0\n",
      "specification__python__requirements_locked__default__gast__version : ==0.2.2\n",
      "specification__python__requirements_locked__default__grpcio__version : ==1.22.0\n",
      "specification__python__requirements_locked__default__h5py__version : ==2.9.0\n",
      "specification__python__requirements_locked__default__keras-applications__version : ==1.0.8\n",
      "specification__python__requirements_locked__default__keras-preprocessing__version : ==1.1.0\n",
      "specification__python__requirements_locked__default__markdown__version : ==3.1.1\n",
      "specification__python__requirements_locked__default__mock__version : ==3.0.5\n",
      "specification__python__requirements_locked__default__numpy__version : ==1.17.0\n",
      "specification__python__requirements_locked__default__protobuf__version : ==3.9.1\n",
      "specification__python__requirements_locked__default__six__version : ==1.12.0\n",
      "specification__python__requirements_locked__default__tensorboard__version : ==1.13.1\n",
      "specification__python__requirements_locked__default__tensorflow-estimator__version : ==1.13.0\n",
      "specification__python__requirements_locked__default__tensorflow__index : pypi-org\n",
      "specification__python__requirements_locked__default__tensorflow__version : ==1.13.1\n",
      "specification__python__requirements_locked__default__termcolor__version : ==1.1.0\n",
      "specification__python__requirements_locked__default__werkzeug__version : ==0.15.5\n",
      "specification__python__requirements_locked__default__wheel__markers : python_version >= '3'\n",
      "specification__python__requirements_locked__default__wheel__version : ==0.33.4\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "Base image\n",
      "=========================================================================\n",
      "\n",
      "Class 1/1\n",
      "specification__base : fedora:28\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "PI (script + sha256 + parameters)\n",
      "=========================================================================\n",
      "\n",
      "Script\n",
      "\n",
      "Class 1/1\n",
      "job_log__script_sha256 : 48a8f416f3b67130e5848f92bd6a1a0914d75498f24f1034d1c2796c33819c95\n",
      "specification__script : https://raw.githubusercontent.com/pacospace/performance/2k-test-new/tensorflow/matmul.py\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "PI parameters\n",
      "\n",
      "Class 1/1\n",
      "job_log__stdout__name : PiMatmul\n",
      "job_log__stdout__@parameters__device : cpu\n",
      "job_log__stdout__@parameters__dtype : float32\n",
      "job_log__stdout__@parameters__matrix_size : 512\n",
      "job_log__stdout__@parameters__reps : 2000\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "Build request (hardware + memory) and Run request (hardware + memory)\n",
      "=========================================================================\n",
      "\n",
      "Build requests\n",
      "\n",
      "Class 1/1\n",
      "specification__build__requests__cpu : 1\n",
      "specification__build__requests__hardware__cpu_family : 6\n",
      "specification__build__requests__hardware__cpu_model : 94\n",
      "specification__build__requests__hardware__physical_cpus : 32\n",
      "specification__build__requests__hardware__processor : Intel Core Processor (Skylake, IBRS)\n",
      "specification__build__requests__memory : 1Gi\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "Run requests\n",
      "\n",
      "Class 1/1\n",
      "specification__run__requests__cpu : 2\n",
      "specification__run__requests__hardware__cpu_family : 6\n",
      "specification__run__requests__hardware__cpu_model : 94\n",
      "specification__run__requests__hardware__physical_cpus : 32\n",
      "specification__run__requests__hardware__processor : Intel Core Processor (Skylake, IBRS)\n",
      "specification__run__requests__memory : 4Gi\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "Failure build (exit_code) and Failure run (exit_code)\n",
      "=========================================================================\n",
      "\n",
      "Build exit_code\n",
      "\n",
      "Class 1/1\n",
      "status__build__exit_code : 0\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "Job exit_code\n",
      "\n",
      "Class 1/1\n",
      "status__job__exit_code : 0\n",
      "job_log__exit_code : 0\n",
      "Number of rows (jobs) is: 300\n"
     ]
    }
   ],
   "source": [
    "tot_reports[\"2k-test-new\"] = create_report(df_total[\"2k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:37.098480Z",
     "start_time": "2019-08-09T09:22:36.860012Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"4k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:23:56.822557Z",
     "start_time": "2019-08-09T09:23:56.785864Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"4k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:42.414525Z",
     "start_time": "2019-08-19T14:04:42.003711Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"4k-test-new\"] = create_report(df_total[\"4k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:39.123494Z",
     "start_time": "2019-08-09T09:22:38.721397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"8k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:23:54.390422Z",
     "start_time": "2019-08-09T09:23:54.342995Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"8k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:02:51.626144Z",
     "start_time": "2019-08-19T14:02:51.253507Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"8k-test-new\"] = create_report(df_total[\"8k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:40.907329Z",
     "start_time": "2019-08-09T09:22:40.662089Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"16k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:23:52.380098Z",
     "start_time": "2019-08-09T09:23:52.330676Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"16k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:47.445879Z",
     "start_time": "2019-08-19T14:04:47.073970Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"16k-test-new\"] = create_report(df_total[\"16k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:43.043836Z",
     "start_time": "2019-08-09T09:22:42.813923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_analysis_plot(batch_identifier=\"20k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:23:49.046652Z",
     "start_time": "2019-08-09T09:23:49.009925Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"20k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:51.578303Z",
     "start_time": "2019-08-19T14:04:51.178640Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"20k-test-new\"] = create_report(df_total[\"20k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results for all reports of the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:44:38.758469Z",
     "start_time": "2019-08-19T14:44:38.751202Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "hardware\n",
      "=====================================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "platform\n",
      "-------------------------------------------------------------------------------\n",
      "processor\n",
      "-------------------------------------------------------------------------------\n",
      "ncpus\n",
      "=====================================================================================\n",
      "software_stack\n",
      "=====================================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "index\n",
      "-------------------------------------------------------------------------------\n",
      "requirements_locked\n",
      "specification__python__requirements_locked__default__protobuf__version: 2\n",
      "=====================================================================================\n",
      "base_image\n",
      "=====================================================================================\n",
      "=====================================================================================\n",
      "pi\n",
      "=====================================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "script\n",
      "job_log__script_sha256: 8\n",
      "specification__script: 8\n",
      "-------------------------------------------------------------------------------\n",
      "parameters\n",
      "job_log__stdout__@parameters__reps: 8\n",
      "=====================================================================================\n",
      "requests\n",
      "=====================================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "build\n",
      "-------------------------------------------------------------------------------\n",
      "run\n",
      "=====================================================================================\n",
      "exit_codes\n",
      "=====================================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "build\n",
      "-------------------------------------------------------------------------------\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "summary = create_feature_summary(extract_results_per_feature(tot_reports))\n",
    "visualize_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:44:39.428101Z",
     "start_time": "2019-08-19T14:44:39.415896Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "hardware\n",
      "=====================================================================================\n",
      "=====================================================================================\n",
      "software_stack\n",
      "=====================================================================================\n",
      "---------------------------------------\n",
      "requirements_locked\n",
      "---------------------------------------\n",
      "\n",
      "specification__python__requirements_locked__default__protobuf__version: ==3.9.1\n",
      "Identifier: 005k-test-new\n",
      "Identifier: 01k-test-new\n",
      "Identifier: 05k-test-new\n",
      "Identifier: 2k-test-new\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "specification__python__requirements_locked__default__protobuf__version: ==3.9.0\n",
      "Identifier: 8k-test-new\n",
      "Identifier: 16k-test-new\n",
      "Identifier: 20k-test-new\n",
      "=====================================================================================\n",
      "base_image\n",
      "=====================================================================================\n",
      "=====================================================================================\n",
      "pi\n",
      "=====================================================================================\n",
      "---------------------------------------\n",
      "script\n",
      "---------------------------------------\n",
      "\n",
      "job_log__script_sha256: 48a8f416f3b67130e5848f92bd6a1a0914d75498f24f1034d1c2796c33819c95\n",
      "Identifier: 2k-test-new\n",
      "\n",
      "job_log__script_sha256: 18913dff7e372a0421fdd401531eabaa4b3bd8bcd90a153e74267f4de5bccde2\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "job_log__script_sha256: eef61427be50bcc1bb8643cd9801c813aaf08f6df6dc76eb9163bb41b6a4ecdb\n",
      "Identifier: 005k-test-new\n",
      "\n",
      "job_log__script_sha256: e06cc0f2c5c021b6706d82f6ea929e9d4bc4bac0b252ff53638ace059c57238e\n",
      "Identifier: 20k-test-new\n",
      "\n",
      "job_log__script_sha256: 79e4e4be41e369c4b41b0d97d74b620d7a42f05e4bc9d0863392c0512c1d6f1d\n",
      "Identifier: 16k-test-new\n",
      "\n",
      "job_log__script_sha256: 7fdf17c9815fad25ed9034eec7a0e331749298d595307f2bca6950bafe63c3db\n",
      "Identifier: 05k-test-new\n",
      "\n",
      "job_log__script_sha256: 7c9557eade759dd0a5593729b17fde95125288a72fe4fafd150f61d19636e6a7\n",
      "Identifier: 01k-test-new\n",
      "\n",
      "job_log__script_sha256: 421e47f26249c105626d2d53795d33b2ce8f63fde6a48a3b6b7e89a8fe380a85\n",
      "Identifier: 8k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/4k-test-new/tensorflow/matmul.py\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/thoth-station/performance/master/tensorflow/matmul.py\n",
      "Identifier: 20k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/8k-test-new/tensorflow/matmul.py\n",
      "Identifier: 8k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/2k-test-new/tensorflow/matmul.py\n",
      "Identifier: 2k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/16k-test-new/tensorflow/matmul.py\n",
      "Identifier: 16k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/005k-test-new/tensorflow/matmul.py\n",
      "Identifier: 005k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/05k-new-test/tensorflow/matmul.py\n",
      "Identifier: 05k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/01k-new-test/tensorflow/matmul.py\n",
      "Identifier: 01k-test-new\n",
      "---------------------------------------\n",
      "parameters\n",
      "---------------------------------------\n",
      "\n",
      "job_log__stdout__@parameters__reps: 8000\n",
      "Identifier: 8k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 4000\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 16000\n",
      "Identifier: 16k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 20000\n",
      "Identifier: 20k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 100\n",
      "Identifier: 01k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 2000\n",
      "Identifier: 2k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 50\n",
      "Identifier: 005k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 500\n",
      "Identifier: 05k-test-new\n",
      "=====================================================================================\n",
      "requests\n",
      "=====================================================================================\n",
      "=====================================================================================\n",
      "exit_codes\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary, debug_summary = create_feature_summary(extract_results_per_feature(tot_reports), debug=True)\n",
    "identify_differences_inspection_results(debug_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:09.933450Z",
     "start_time": "2019-08-19T14:29:09.884716Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_parameter = {\n",
    "    \"job_duration\": \"job_duration\",\n",
    "    \"build_duration\": \"build_duration\",\n",
    "    \"created\": \"created\",\n",
    "    \"status__job__finished_at\": \"job_finished\",\n",
    "    \"job_log__stdout__@result__elapsed\": \"elapsed\",\n",
    "    \"job_log__stdout__@result__rate\": \"rate\",\n",
    "    \"job_log__usage__ru_utime\": \"utime\",\n",
    "    \"job_log__usage__ru_stime\": \"stime\",\n",
    "    \"job_log__usage__ru_nvcsw\": \"nvcsw\",\n",
    "    \"job_log__usage__ru_nivcsw\": \"nivcsw\"\n",
    "}\n",
    "dftotal = pd.DataFrame()\n",
    "parameters = []\n",
    "\n",
    "for key, parameter in mapping_parameter.items():\n",
    "    for identifier in identifier_inspection:\n",
    "        parameters.append(parameter)\n",
    "        dftotal[parameter + \"_\" + str(identifier.split(\"-\")[0])] = df_total[identifier][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:11.055612Z",
     "start_time": "2019-08-19T14:29:10.876619Z"
    }
   },
   "outputs": [],
   "source": [
    "dftotal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:11.254284Z",
     "start_time": "2019-08-19T14:29:11.248830Z"
    }
   },
   "outputs": [],
   "source": [
    "batches = {}\n",
    "\n",
    "for parameter in parameters:\n",
    "    batches[parameter] = create_batches_filter(\n",
    "        parameter=parameter,\n",
    "        inspection_batch_names=identifier_inspection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms of the batches for job_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:12.496979Z",
     "start_time": "2019-08-19T14:29:12.326973Z"
    }
   },
   "outputs": [],
   "source": [
    "dftotal[batches[\"job_duration\"]].iplot(kind=\"histogram\", bins=15, theme=\"white\", title=\"Job duration distribution per batch\",\n",
    "         xTitle='Inspection Time [s]', yTitle='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the job_duration batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:13.650588Z",
     "start_time": "2019-08-19T14:29:13.539654Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"job_duration\"], y_label=\"Time [s]\", title_box=\"Box plots job duration per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the elapsed batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:40:59.437628Z",
     "start_time": "2019-08-19T14:40:59.315134Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"elapsed\"], y_label=\"Elapsed [ms]\", title_box=\"Box plots elapsed time per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the rate batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:04.784095Z",
     "start_time": "2019-08-19T14:41:04.669737Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"rate\"], y_label=\"Rate [GFLOPS]\",title_box=\"Box plots rate per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the utime batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:08.652080Z",
     "start_time": "2019-08-19T14:41:08.502758Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"utime\"], y_label=\"Time [s]\", title_box=\"Box plots utime per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the stime batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:11.930253Z",
     "start_time": "2019-08-19T14:41:11.816945Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"stime\"], y_label=\"Time [s]\", title_box=\"Box plots stime per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the nvcsw batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:14.920063Z",
     "start_time": "2019-08-19T14:41:14.815936Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"nvcsw\"], y_label=\"Context Switches []\", title_box=\"Box plots nvcsw per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the nivcsw batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:18.838298Z",
     "start_time": "2019-08-19T14:41:18.729925Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"nivcsw\"], y_label=\"Context Switches []\", title_box=\"Box plots nivcsw per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T14:09:40.608065Z",
     "start_time": "2019-08-06T14:09:40.605168Z"
    }
   },
   "source": [
    "# Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:19.534156Z",
     "start_time": "2019-08-19T14:29:19.448600Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_parameter = {\n",
    "    \"job_duration\": \"job_duration\",\n",
    "    \"job_log__stdout__@result__elapsed\": \"elapsed\",\n",
    "    \"job_log__stdout__@result__rate\": \"rate\",\n",
    "    \"job_log__usage__ru_utime\": \"utime\",\n",
    "    \"job_log__usage__ru_stime\": \"stime\",\n",
    "    \"job_log__usage__ru_nvcsw\": \"nvcsw\",\n",
    "    \"job_log__usage__ru_nivcsw\": \"nivcsw\"\n",
    "}   \n",
    "\n",
    "dftotal_statistics = {}\n",
    "for key, parameter in mapping_parameter.items():\n",
    "    dftotal_statistics[parameter] = evaluate_statistics_per_parameter(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation for `job_duration` and `elapsed_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:20.830420Z",
     "start_time": "2019-08-19T14:29:20.599839Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"job_duration\", \"elapsed\"]\n",
    "colour = [\"g\", \"b\"]\n",
    "quantity = \"std\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel= \"Time [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:21.663271Z",
     "start_time": "2019-08-19T14:29:21.436917Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"elapsed\"]\n",
    "colour = [\"b\"]\n",
    "quantity = \"std\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel= \"Time [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:21.907111Z",
     "start_time": "2019-08-19T14:29:21.682820Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"job_duration\", \"elapsed\"]\n",
    "colour = [\"g\", \"b\"]\n",
    "quantity = \"std_error\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel= \"Time [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:22.380434Z",
     "start_time": "2019-08-19T14:29:22.118033Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"job_duration\", \"elapsed\", \"rate\"]\n",
    "colour = [\"g\", \"b\", \"r\"]\n",
    "quantity = \"cv\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel=\"CV [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plots interpolated for `job_duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:25.142063Z",
     "start_time": "2019-08-19T14:29:24.883466Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameter_selected = \"job_duration\"\n",
    "colour = [\"g\", \"b\", \"b\", \"r\", \"y\", \"k\"]\n",
    "quantities = [\"median\", \"q1\", \"q3\", \"max\", \"min\", \"iqr\"]\n",
    "plot_batches_statistics_interpolated_single_parameter(parameter_selected=parameter_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantities=quantities,\n",
    "                                    title_ylabel= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plots interpolated for `elapsed_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:27.291146Z",
     "start_time": "2019-08-19T14:29:26.882132Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameter_selected = \"elapsed\"\n",
    "colour = [\"g\", \"b\", \"b\", \"r\", \"y\", \"k\"]\n",
    "quantities = [\"median\", \"q1\", \"q3\", \"max\", \"min\", \"iqr\"]\n",
    "plot_batches_statistics_interpolated_single_parameter(parameter_selected=parameter_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantities=quantities,\n",
    "                                    title_ylabel= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between `ru_utime` and `ru_nivcsw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:21.118958Z",
     "start_time": "2019-08-19T13:58:20.964961Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"005k\",\n",
    "    \"01k\",\n",
    "    \"05k\",\n",
    "    \"2k\",\n",
    "    \"4k\",\n",
    "    \"8k\",\n",
    "    \"16k\",\n",
    "    \"20k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:25.303101Z",
     "start_time": "2019-08-19T13:58:25.189793Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"4k\",\n",
    "    \"8k\",\n",
    "    \"16k\",\n",
    "    \"20k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:29.020719Z",
     "start_time": "2019-08-19T13:58:28.914704Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"05k\",\n",
    "    \"2k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:32.750965Z",
     "start_time": "2019-08-19T13:58:32.639873Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"005k\",\n",
    "    \"01k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:39.306997Z",
     "start_time": "2019-08-19T13:58:39.301649Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_plot(data: pd.DataFrame,\n",
    "               x_axis_columns: str,\n",
    "               y_axis_columns: str,\n",
    "               title_plot: str = \"Box plot\",\n",
    "               x_label: str = \"\",\n",
    "               y_label: str = \"Variable [Measurement Unit]\"):\n",
    "    \"\"\"Create plot using two columns of the DataFrame.\"\"\"\n",
    "    figure = py.iplot(\n",
    "    {\n",
    "        'data': [\n",
    "            {\n",
    "                'x': df_tot_time[x_axis_columns],\n",
    "                'y': df_tot_time[y_axis_columns],\n",
    "                'mode': 'lines+markers',\n",
    "            } \n",
    "        ],\n",
    "        'layout': {\n",
    "            'xaxis': {'title': x_label},\n",
    "            'yaxis': {'title': y_label}\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:42.553125Z",
     "start_time": "2019-08-19T13:58:42.541061Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_time_builds = []\n",
    "tot_time_jobs = []\n",
    "tot_time_sum_builds_and_jobs = []\n",
    "n_parallel = 6\n",
    "for identifier in identifier_inspection:\n",
    "    tot_time_builds.append(sum(dftotal[\"build_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel)\n",
    "    tot_time_jobs.append(sum(dftotal[\"job_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel)\n",
    "    tot_time_sum_builds_and_jobs.append(\n",
    "    (sum(dftotal[\"build_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel) + (sum(dftotal[\"job_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel))\n",
    "df_tot_time = pd.DataFrame()\n",
    "df_tot_time[\"batches\"] = identifier_inspection\n",
    "df_tot_time[\"builds_time\"] = tot_time_builds\n",
    "df_tot_time[\"jobs_time\"] = tot_time_jobs\n",
    "df_tot_time[\"tot_time\"] = tot_time_sum_builds_and_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection Builds Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:43.933517Z",
     "start_time": "2019-08-19T13:58:43.839571Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plot(df_tot_time, \n",
    "            x_axis_columns= \"batches\",\n",
    "            y_axis_columns= \"builds_time\",\n",
    "            title_plot=\"Time spent to evaluate all inspections builds in hours\",\n",
    "            x_label=\"Batch Identifier\", \n",
    "            y_label=\"Tot Time for builds [h]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection Jobs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:45.074656Z",
     "start_time": "2019-08-19T13:58:44.973411Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plot(df_tot_time, \n",
    "            x_axis_columns= \"batches\",\n",
    "            y_axis_columns= \"jobs_time\",\n",
    "            title_plot=\"Time spent to evaluate all inspections jobs in hours (ASSUMPTIONS ~6 in parallel)\",\n",
    "            x_label=\"Batch Identifier\", \n",
    "            y_label=\"Tot Time for jobs [h]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection builds + Jobs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:46.375646Z",
     "start_time": "2019-08-19T13:58:46.077067Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plot(df_tot_time, \n",
    "            x_axis_columns= \"batches\",\n",
    "            y_axis_columns= \"tot_time\",\n",
    "            title_plot=\"Time spent to evaluate all inspections buids + jobs in hours (ASSUMPTIONS ~6 in parallel)\",\n",
    "            x_label=\"Batch Identifier\", \n",
    "            y_label=\"Tot Time for builds + jobs [h]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch has ~300 inspections jobs. During the analysis, two different software stacks have been identified [Reference](#Visualize-results-for-all-reports-of-the-batches). It could be necessary to repeat some batches for consistency, fixing also the dependencies required by tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Boxplot](#Boxplot-of-the-job_duration-batches) and [Interpolation](#Box-Plots-interpolated-for-job_duration) we can see that the error for `job_duration` is increasing with repetitions.\n",
    "\n",
    "Looking at the [Boxplot](#Boxplot-of-the-elapsed-batches) and [Interpolation](#Box-Plots-interpolated-for-elapsed_time) we can see that the error for the `elapsed time` is minimized around 2k Repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T10:06:58.145116Z",
     "start_time": "2019-08-09T10:06:58.141245Z"
    }
   },
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between [`ru_utime` and `ru_nivcsw`](#Correlation-between-ru_utime-and-ru_nivcsw) do not show possible correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated [time](#Time-analysis) for jobs is obtained assuming `number of builds and jobs running in parallel` according to the memory required, respectively 1Gb and 4Gb, for the available space in the namespace (32Gb). This is an approximation because in practice there are also graph-sync jobs running in the same namespace, therefore using resources of the namespace that should be used by the builds and jobs. \n",
    "It's also important to consider that Build time is also affected by the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "465.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
