{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-dataframe-per-batch\" data-toc-modified-id=\"Create-dataframe-per-batch-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Create dataframe per batch</a></span></li></ul></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-0.05k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-0.05k-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 0.05k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-0.1k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-0.1k-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 0.1k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-0.5k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-0.5k-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 0.5k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-2k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-2k-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 2k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-4k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-4k-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 4k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-8k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-8k-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 8k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-16k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-16k-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 16k</a></span></li><li><span><a href=\"#Analyze-batch-with-number-of-Repetitions:-20k\" data-toc-modified-id=\"Analyze-batch-with-number-of-Repetitions:-20k-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Analyze batch with number of Repetitions: 20k</a></span></li><li><span><a href=\"#Visualize-results-for-all-reports-of-the-batches\" data-toc-modified-id=\"Visualize-results-for-all-reports-of-the-batches-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Visualize results for all reports of the batches</a></span></li><li><span><a href=\"#Error-analysis\" data-toc-modified-id=\"Error-analysis-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Error analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Histograms-of-the-batches-for-job_duration\" data-toc-modified-id=\"Histograms-of-the-batches-for-job_duration-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Histograms of the batches for job_duration</a></span></li><li><span><a href=\"#Boxplot-of-the-job_duration-batches\" data-toc-modified-id=\"Boxplot-of-the-job_duration-batches-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Boxplot of the job_duration batches</a></span></li><li><span><a href=\"#Boxplot-of-the-elapsed-batches\" data-toc-modified-id=\"Boxplot-of-the-elapsed-batches-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>Boxplot of the elapsed batches</a></span></li><li><span><a href=\"#Boxplot-of-the-rate-batches\" data-toc-modified-id=\"Boxplot-of-the-rate-batches-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;</span>Boxplot of the rate batches</a></span></li><li><span><a href=\"#Boxplot-of-the-utime-batches\" data-toc-modified-id=\"Boxplot-of-the-utime-batches-11.5\"><span class=\"toc-item-num\">11.5&nbsp;&nbsp;</span>Boxplot of the utime batches</a></span></li><li><span><a href=\"#Boxplot-of-the-stime-batches\" data-toc-modified-id=\"Boxplot-of-the-stime-batches-11.6\"><span class=\"toc-item-num\">11.6&nbsp;&nbsp;</span>Boxplot of the stime batches</a></span></li><li><span><a href=\"#Boxplot-of-the-nvcsw-batches\" data-toc-modified-id=\"Boxplot-of-the-nvcsw-batches-11.7\"><span class=\"toc-item-num\">11.7&nbsp;&nbsp;</span>Boxplot of the nvcsw batches</a></span></li><li><span><a href=\"#Boxplot-of-the-nivcsw-batches\" data-toc-modified-id=\"Boxplot-of-the-nivcsw-batches-11.8\"><span class=\"toc-item-num\">11.8&nbsp;&nbsp;</span>Boxplot of the nivcsw batches</a></span></li></ul></li><li><span><a href=\"#Interpolations\" data-toc-modified-id=\"Interpolations-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Interpolations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-Deviation-for-job_duration-and-elapsed_time\" data-toc-modified-id=\"Standard-Deviation-for-job_duration-and-elapsed_time-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Standard Deviation for <code>job_duration</code> and <code>elapsed_time</code></a></span></li><li><span><a href=\"#Box-Plots-interpolated-for-job_duration\" data-toc-modified-id=\"Box-Plots-interpolated-for-job_duration-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Box Plots interpolated for <code>job_duration</code></a></span></li><li><span><a href=\"#Box-Plots-interpolated-for-elapsed_time\" data-toc-modified-id=\"Box-Plots-interpolated-for-elapsed_time-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>Box Plots interpolated for <code>elapsed_time</code></a></span></li></ul></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Correlations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Correlation-between-ru_utime-and-ru_nivcsw\" data-toc-modified-id=\"Correlation-between-ru_utime-and-ru_nivcsw-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>Correlation between <code>ru_utime</code> and <code>ru_nivcsw</code></a></span></li><li><span><a href=\"#Correlation-between-ru_utime-and-ru_nvcsw\" data-toc-modified-id=\"Correlation-between-ru_utime-and-ru_nvcsw-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;</span>Correlation between <code>ru_utime</code> and <code>ru_nvcsw</code></a></span></li></ul></li><li><span><a href=\"#Inspection-Time-analysis\" data-toc-modified-id=\"Inspection-Time-analysis-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Inspection Time analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inspection-Builds-Time\" data-toc-modified-id=\"Inspection-Builds-Time-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>Inspection Builds Time</a></span></li><li><span><a href=\"#Inspection-Jobs-Time\" data-toc-modified-id=\"Inspection-Jobs-Time-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>Inspection Jobs Time</a></span></li><li><span><a href=\"#Inspection-builds-+-Jobs-Time\" data-toc-modified-id=\"Inspection-builds-+-Jobs-Time-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Inspection builds + Jobs Time</a></span></li></ul></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Conclusions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Statistics\" data-toc-modified-id=\"Statistics-15.1\"><span class=\"toc-item-num\">15.1&nbsp;&nbsp;</span>Statistics</a></span></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-15.2\"><span class=\"toc-item-num\">15.2&nbsp;&nbsp;</span>Correlations</a></span></li><li><span><a href=\"#Time\" data-toc-modified-id=\"Time-15.3\"><span class=\"toc-item-num\">15.3&nbsp;&nbsp;</span>Time</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to get a notion about error rate of inspection jobs which are run on Amun API, using the following inputs:\n",
    "\n",
    "- TensorFlow 1.13 from pypi\n",
    "- fedora base image\n",
    "- matmul (tensorflow, matrix size 512, `repetitions` , float32)\n",
    "- 300 inspections\n",
    "- CPU only\n",
    "\n",
    "\n",
    "We want to understand how the error behave for different period of time/`number of repetitions` requested for an inspection. We want to understand if we can eliminate noise inside the environment. We want to find out if we can \"configure\" the error rate in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:34.893385Z",
     "start_time": "2019-08-19T11:23:34.889533Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import functools\n",
    "import re\n",
    "\n",
    "import textwrap\n",
    "import typing\n",
    "\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "from typing import Callable, Iterable\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:38.284663Z",
     "start_time": "2019-08-19T11:23:35.247360Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import thoth.lab.underscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from thoth.storages import InspectionResultsStore\n",
    "from thoth.lab import inspection\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 800)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:38.416139Z",
     "start_time": "2019-08-19T11:23:38.286062Z"
    }
   },
   "outputs": [],
   "source": [
    "import cufflinks as cf\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "\n",
    "from plotly import graph_objs as go\n",
    "from plotly import figure_factory as ff\n",
    "from plotly import tools\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "# plotly\n",
    "init_notebook_mode()\n",
    "\n",
    "# cufflinks\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:33:46.371049Z",
     "start_time": "2019-08-20T10:33:46.312327Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_inspection_list(ids_list: List[str], identifier_list: List[str]) -> dict: \n",
    "    \"\"\"Filter inspection ids list according to the identifier selected\"\"\"\n",
    "    filtered_list_ids = {}\n",
    "\n",
    "    for identifier in identifier_list:\n",
    "        filtered_list_ids[identifier] = []\n",
    "\n",
    "    for ids in ids_list:\n",
    "        inspection_filter = \"-\".join(ids.split(\"-\")[1:(len(ids.split(\"-\")) - 1)])\n",
    "        if inspection_filter:\n",
    "            if inspection_filter in identifier_list:\n",
    "                filtered_list_ids[inspection_filter].append(ids)\n",
    "                \n",
    "    tot_inspections_selected = sum([len(batch_n) for batch_n in filtered_list_ids.values()])\n",
    "    inspection_batches = [(batch_name, len(batch_count)) for batch_name, batch_count in filtered_list_ids.items()]\n",
    "    print(f\"There are {tot_inspections_selected} inspection runs!: {inspection_batches} respectively\")\n",
    "    \n",
    "    return filtered_list_ids\n",
    "\n",
    "\n",
    "def create_inspection_analysis_plots(df_duration_batches: pd.DataFrame, batch_identifier: str):\n",
    "    \"Create inspection analysis plots per batch\"\n",
    "    # Box plots job duration and build duration\n",
    "    fig = inspection.create_duration_box(df_duration_batches[batch_identifier], [\"build_duration\", \"job_duration\"])\n",
    "\n",
    "    py.iplot(fig)\n",
    "    # Scatter job duration\n",
    "    fig = inspection.create_duration_scatter(\n",
    "        df_duration_batches[batch_identifier], \"job_duration\", title=\"InspectionRun job duration\"\n",
    "    )\n",
    "\n",
    "    py.iplot(fig)\n",
    "    # Scatter build duration\n",
    "    fig = inspection.create_duration_scatter(\n",
    "        df_duration_batches[batch_identifier], \"build_duration\", title=\"InspectionRun build duration\"\n",
    "    )\n",
    "\n",
    "    py.iplot(fig)\n",
    "    # Histogram\n",
    "    fig = inspection.create_duration_histogram(df_duration_batches[batch_identifier], [\"job_duration\"])\n",
    "\n",
    "    py.iplot(fig)\n",
    "\n",
    "    \n",
    "def create_box_plot(data: pd.DataFrame,\n",
    "               columns: Union[str, List[str]] = None,\n",
    "               title_box: str = \"Box plot\",\n",
    "               y_label: str = \"Variable [Measurement Unit]\",\n",
    "               static: str = False):\n",
    "    \"\"\"Create duration Box plot.\"\"\"\n",
    "    columns = columns if columns is not None else data[columns].columns     \n",
    "        \n",
    "    figure = data[columns].iplot(\n",
    "        kind=\"box\", title=title_box, yTitle=y_label, asFigure=True\n",
    "    )\n",
    "\n",
    "    return figure\n",
    "\n",
    "\n",
    "def create_batches_filter(parameter: str, inspection_batch_names: list) -> List:\n",
    "    \"\"\"Create batch filter for plots.\"\"\"\n",
    "    batches_list = []\n",
    "    for identifier in inspection_batch_names:\n",
    "        batches_list.append(parameter + \"_\" + str(identifier.split(\"-\")[0]))\n",
    "        \n",
    "    return batches_list\n",
    "\n",
    "\n",
    "def create_scatter_and_correlation(data: pd.DataFrame,\n",
    "                                  columns: Union[str, List[str]] = None,\n",
    "                                  title_scatter: str = \"Scatter plot\"):\n",
    "    \"\"\"Create Scatter plot and evaluate correlation coefficients.\"\"\"\n",
    "    columns = columns if columns is not None else data[columns].columns\n",
    "\n",
    "    figure = data[columns].iplot(\n",
    "        kind=\"scatter\",\n",
    "        x=columns[0],\n",
    "        y=columns[1],\n",
    "        title=title_scatter,\n",
    "        xTitle=columns[0],\n",
    "        yTitle=columns[1],\n",
    "        mode='markers',\n",
    "        asFigure=True\n",
    "    )\n",
    "    \n",
    "    for correlation_type in [\"pearson\", \"spearman\", \"kendall\"]:\n",
    "        correlation_matrix = data[columns].corr(correlation_type)\n",
    "        print(f\"\\n{correlation_type} correlation results:\\n{correlation_matrix}\")\n",
    "    \n",
    "    return figure\n",
    "\n",
    "\n",
    "def create_scatter_plots_for_multiple_batches(data: pd.DataFrame,\n",
    "                                  columns: Union[str, List[str]] = None,\n",
    "                                  list_batches: List[str] = [], \n",
    "                                  title_scatter: str = \"Scatter plot\",\n",
    "                                  x_label: str = \" \", \n",
    "                                  y_label: str = \" \"):\n",
    "    \"\"\"Create Scatter plots for multiple batches.\"\"\"\n",
    "    columns = columns if columns is not None else data[columns].columns\n",
    "\n",
    "    figure = {\n",
    "    'data': [\n",
    "        {\n",
    "            'x': data[columns[0] + '_' + batch],\n",
    "            'y': data[columns[1] + '_' + batch],\n",
    "            'name': batch, 'mode': 'markers',\n",
    "        } for batch in list_batches\n",
    "    ],\n",
    "    'layout': {\n",
    "        'title': title_scatter,\n",
    "        'xaxis': {'title': x_label},\n",
    "        'yaxis': {'title': y_label}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return figure\n",
    "\n",
    "\n",
    "def evaluate_statistics(df_batch: pd.DataFrame, parameter_name: str) -> Dict:\n",
    "    \"\"\"Evaluate statistical quantities for plots\"\"\"\n",
    "    cv = df_batch[parameter_name].std()/df_batch[parameter_name].mean()*100\n",
    "    std_error = df_batch[parameter_name].std()/np.sqrt(df_batch[parameter_name].shape[0])\n",
    "    std = df_batch[parameter_name].std()\n",
    "    median = df_batch[parameter_name].median()\n",
    "    q = df_batch[parameter_name].quantile([.25, .75])\n",
    "    q1 =  q[0.25]\n",
    "    q3 =  q[0.75]\n",
    "    IQR = q3 - q1\n",
    "    maxr = df_batch[parameter_name].max()\n",
    "    minr = df_batch[parameter_name].min()\n",
    "\n",
    "    return {\"cv\": cv,\n",
    "            \"std_error\": std_error,\n",
    "            \"std\": std,\n",
    "            \"median\": median,\n",
    "            \"q1\":q1,\n",
    "            \"q3\": q3,\n",
    "            \"iqr\": IQR,\n",
    "            \"max\": maxr,\n",
    "            \"min\": minr}\n",
    "\n",
    "\n",
    "def evaluate_statistics_per_parameter_per_batch(dict_of_df_batches: dict, parameter: str) -> dict:\n",
    "    \"\"\"Aggregate results of statistics per parameter from different inspection batches\"\"\"\n",
    "    results_statistics = {}\n",
    "    for identifier in identifier_inspection:\n",
    "        results_statistics[identifier] = evaluate_statistics(\n",
    "            df_batch=dict_of_df_batches[identifier],\n",
    "            parameter_name=parameter)\n",
    "        \n",
    "    results = {}\n",
    "    \n",
    "    for quantity in results_statistics[identifier].keys():\n",
    "        results[quantity] = [values[quantity] for values in results_statistics.values()]\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_batches_statistics_interpolated_single_parameter(parameter_selected: str,\n",
    "                                                          colour_list: List,\n",
    "                                                          quantities: List,\n",
    "                                                          title_ylabel: str = \" \"):\n",
    "    \"\"\"Plot interpolated statistics for different batches for a specific parameter\"\"\"\n",
    "    if len(colour_list) != len(quantities):\n",
    "        logger.exception(f\"List of statistical quantities and List of colours need to have the same length!\")\n",
    "    i = 0\n",
    "    parameter_results = dftotal_statistics[parameter_selected]\n",
    "    for quantity in quantities:\n",
    "        plt.plot(identifier_inspection, parameter_results[quantity], f'{colour[i]}o-', label=f'{quantity}')\n",
    "        i += 1\n",
    "    plt.xlabel('Batch Identifier')\n",
    "    plt.ylabel(title_ylabel)\n",
    "    plt.title(f'Statistics plot for {parameter_selected} of different batch')\n",
    "    plt.tick_params(axis='x', rotation=45)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_batches_statistics_interpolated_multiple_parameters(parameters_selected: List,\n",
    "                                                              colour_list: List,\n",
    "                                                              quantity: str,\n",
    "                                                              title_ylabel: str = \" \"):\n",
    "    \"\"\"Plot single interpolated statistics for different batches for multiple parameters\"\"\"\n",
    "    if len(colour_list) != len(parameters_selected):\n",
    "        logger.exception(f\"List of parameters and List of colours need to have the same length!\")\n",
    "    i = 0\n",
    "    for parameter in parameters_selected:\n",
    "        parameter_results = dftotal_statistics[parameter]\n",
    "        plt.plot(identifier_inspection, parameter_results[quantity], f'{colour[i]}o-', label=f'{parameter}')\n",
    "        i += 1\n",
    "    plt.xlabel('Batch Identifier')\n",
    "    plt.ylabel(title_ylabel)\n",
    "    plt.title(f'Statistics plot for {quantity} of different batch for different parameters')\n",
    "    plt.tick_params(axis='x', rotation=45)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def show_categories(inspection_df: pd.DataFrame):\n",
    "    \"\"\"List categories in the given DataFrame.\"\"\"\n",
    "    index = inspection_df.index.droplevel(-1).unique()\n",
    "\n",
    "    results_categories = {}\n",
    "    for n, idx in enumerate(index.values):\n",
    "        print(\"\\nClass {}/{}\".format(n + 1, len(index)))\n",
    "        \n",
    "        class_results = {}\n",
    "        if len(index.names) > 1:\n",
    "            for name, ind in zip(index.names, idx):\n",
    "                print(f\"{name} :\", ind)\n",
    "                class_results[name] = ind\n",
    "        else:\n",
    "            print(f\"{index.names[0]} :\", idx)\n",
    "            class_results[index.names[0]] = idx\n",
    "        results_categories[n + 1] = class_results\n",
    "\n",
    "        frame = inspection_df.loc[idx]\n",
    "        print(\"Number of rows (jobs) is:\", frame.shape[0])\n",
    "        \n",
    "    return results_categories\n",
    "\n",
    "\n",
    "_INSPECTION_REPORT_FEATURES = {\n",
    "    \"hardware\" : [\"platform\", \"processor\", \"ncpus\"],\n",
    "    \"software_stack\" : [\"index\", \"requirements_locked\"],\n",
    "    \"base_image\": [],\n",
    "    \"pi\": [\"script\", \"parameters\"],\n",
    "    \"requests\": [\"build\", \"run\"],\n",
    "    \"exit_codes\": [\"build\", \"run\"]\n",
    "}\n",
    "\n",
    "_INSPECTION_JSON_DF_KEYS_FEATURES_MAPPING = {\n",
    "    \"platform\": [\"platform\"],\n",
    "    \"processor\": [\"job_log__hwinfo__cpu__is\", \"job_log__hwinfo__cpu__has\"], \n",
    "    \"ncpus\" : [\"ncpus\"],\n",
    "    \"index\": [\"index\"],\n",
    "    \"requirements_locked\": [\"specification__python__requirements_locked__default\"],\n",
    "    \"base_image\": [\"base\"],\n",
    "    \"script\": [\"script\", \"script_sha256\"],\n",
    "    \"parameters\": [\"name\", \"@parameters\"],\n",
    "    \"build_requests\": [\"build__requests\"],\n",
    "    \"run_requests\": [\"run__requests\"],\n",
    "    \"build_exit_code\": [\"build__exit_code\"],\n",
    "    \"job_exit_code\": [\"job__exit_code\", \"job_log__exit_code\"]\n",
    "    \n",
    "}\n",
    "\n",
    "def create_report(df_inspection_batch: pd.DataFrame):\n",
    "    \"\"\"Create report describing the batch of inspection jobs for the different features.\"\"\"\n",
    "    report_results = {}\n",
    "    for feature, sub_features in _INSPECTION_REPORT_FEATURES.items():\n",
    "        report_results[feature] = {}\n",
    "        print()\n",
    "        print(\"=========================================================================\")\n",
    "        print(f\"{feature}\")\n",
    "        print(\"=========================================================================\")\n",
    "        if sub_features:\n",
    "            for sub_feature in sub_features:\n",
    "                print()\n",
    "                print(\"-------------------------------------------------------------------------\")\n",
    "                print(f\"{feature} -> {sub_feature}\")\n",
    "                print(\"-------------------------------------------------------------------------\")\n",
    "                sub_feature_result = inspection.query_inspection_dataframe(\n",
    "                    df_inspection_batch,\n",
    "                    groupby=_INSPECTION_JSON_DF_KEYS_FEATURES_MAPPING[sub_feature],\n",
    "                    exclude=\"node\")\n",
    "                report_results[feature][sub_feature] = show_categories(sub_feature_result)\n",
    "        else:\n",
    "            feature_result = inspection.query_inspection_dataframe(\n",
    "                df_inspection_batch,\n",
    "                groupby=_INSPECTION_JSON_DF_KEYS_FEATURES_MAPPING[feature],\n",
    "                exclude=\"node\")\n",
    "            report_results[feature] = show_categories(sub_feature_result)\n",
    "    \n",
    "    return report_results\n",
    "\n",
    "\n",
    "def create_feature_summary(batches_reports: dict, debug: bool = False) -> dict:\n",
    "    \"\"\"Create summary of number of combinations per features\"\"\"\n",
    "    results_features = _aggreagate_results_per_feature(batches_reports)\n",
    "    features_summary = {}\n",
    "    debug_summary = {}\n",
    "    for feature, feature_results in results_features.items():\n",
    "        debug_summary[feature] = {}\n",
    "        \n",
    "        if type(feature_results) != list:\n",
    "            features_summary[feature] = {}\n",
    "            \n",
    "            for sub_feature, sub_feature_results in feature_results.items():\n",
    "                debug_summary[feature][sub_feature] = {}\n",
    "                keys = [key for key in sub_feature_results[0].keys()]\n",
    "                key_counts = {}\n",
    "                \n",
    "                for key in keys:\n",
    "                    \n",
    "                    key_counts[key] = len(set([k[key] for k in results_features[feature][sub_feature]]))\n",
    "                    \n",
    "                    if key_counts[key] != 1:\n",
    "                        debug_summary[feature][sub_feature][key] = set([k[key] for k in results_features[feature][sub_feature]])\n",
    "                        \n",
    "                features_summary[feature][sub_feature] = key_counts\n",
    "        else:\n",
    "            keys = [key for key in feature_results[0].keys()]\n",
    "            key_counts = {}\n",
    "            \n",
    "            for key in keys:\n",
    "                key_counts[key] = len(set([k[key] for k in results_features[feature]]))\n",
    "                \n",
    "                if key_counts[key] != 1:\n",
    "                    debug_summary[feature][key] = set([k[key] for k in results_features[feature]])\n",
    "                    \n",
    "            features_summary[feature] = key_counts\n",
    "    if debug:\n",
    "        return _visualize_differences_in_inspection_results(debug_summary)\n",
    "    \n",
    "    return _visualize_summary(features_summary)\n",
    "\n",
    "\n",
    "def _aggreagate_results_per_feature(batches_reports: dict) -> dict:\n",
    "    \"\"\"Aggregate results for all features across all batches\"\"\"\n",
    "    results_per_feature_per_batch = {}\n",
    "    \n",
    "    for feature, sub_features in _INSPECTION_REPORT_FEATURES.items():\n",
    "        for batch in batches_reports.keys():\n",
    "            \n",
    "            if sub_features:\n",
    "                if feature not in results_per_feature_per_batch.keys():\n",
    "                    results_per_feature_per_batch[feature] = {}\n",
    "                    \n",
    "                for sub_feature in sub_features:\n",
    "                    \n",
    "                    if sub_feature not in results_per_feature_per_batch[feature].keys():\n",
    "                        results_per_feature_per_batch[feature][sub_feature] = []\n",
    "                        \n",
    "                    for k, v in batches_reports[batch][feature][sub_feature].items():\n",
    "                        results_per_feature_per_batch[feature][sub_feature].append(batches_reports[batch][feature][sub_feature][k])\n",
    "            else:\n",
    "                \n",
    "                if feature not in results_per_feature_per_batch.keys():\n",
    "                    results_per_feature_per_batch[feature] = []\n",
    "                    \n",
    "                for k, v in batches_reports[batch][feature].items():\n",
    "                    results_per_feature_per_batch[feature].append(batches_reports[batch][feature][k])\n",
    "                    \n",
    "    return results_per_feature_per_batch\n",
    "\n",
    "\n",
    "def _visualize_summary(summary_results: dict):\n",
    "    \"\"\"Visualize summary of results (if there are any differences)\"\"\"\n",
    "    for feature, feature_results in summary.items():\n",
    "        print()\n",
    "        print(\"===============================================================================\")\n",
    "        print(f\"{feature}\")\n",
    "        print(\"===============================================================================\")\n",
    "        if len(feature_results) > 1:\n",
    "            for sub_feature, sub_feature_results in feature_results.items():\n",
    "                print(\"---------------------------------------------------------------------------\")\n",
    "                print(sub_feature)\n",
    "                for key, count in sub_feature_results.items():\n",
    "                    if count > 1:\n",
    "                        print(f\"{key}: {count}\")\n",
    "        else:\n",
    "            for key, count in feature_results.items():\n",
    "                if count > 1:\n",
    "                    print(\"===========================================================================================\")\n",
    "                    print(feature)\n",
    "                    print(\"===========================================================================================\")\n",
    "                    print(f\"{key}: {count}\")\n",
    "\n",
    "\n",
    "def _visualize_differences_in_inspection_results(summary_debug: dict):\n",
    "    \"\"\"Function to identify and visualize differences in batches for the different features\"\"\"\n",
    "    for feature, feature_results in summary_debug.items():\n",
    "        print()\n",
    "        print(\"=========================================================================\")\n",
    "        print(f\"{feature}\")\n",
    "        print(\"=========================================================================\")\n",
    "        if summary_debug[feature]:\n",
    "            for sub_feature, sub_feature_results in feature_results.items():\n",
    "                if sub_feature_results:\n",
    "                    print(\"-------------------------------------------------\")\n",
    "                    print(sub_feature)\n",
    "                    print(\"-------------------------------------------------\")\n",
    "                    for key_sf in sub_feature_results.keys():\n",
    "                        for value in sub_feature_results[key_sf]:\n",
    "                            print()\n",
    "                            print(f\"{key_sf}: {value}\")\n",
    "                            for batch, batch_results in tot_reports.items():\n",
    "                                for b, r in batch_results[feature][sub_feature].items():\n",
    "                                    if r[key_sf] == value:\n",
    "                                        print(\"Identifier:\", batch)\n",
    "        else:\n",
    "            if feature_results:\n",
    "                for key_f in feature_results.keys():\n",
    "                    for value in sub_feature_results[key_f]:\n",
    "                        print(\"=========================================================================\")\n",
    "                        print()\n",
    "                        print(f\"{key_f}: {value}\")\n",
    "                        for batch, batch_results in tot_reports.items():\n",
    "                            for b, r in batch_results[feature].items():\n",
    "                                if r[key_f] == value:\n",
    "                                    print(\"Identifier:\", batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T12:54:34.955207Z",
     "start_time": "2019-08-19T12:54:34.935638Z"
    }
   },
   "outputs": [],
   "source": [
    "%env THOTH_DEPLOYMENT_NAME     thoth-core-psi-stage\n",
    "%env THOTH_CEPH_BUCKET         thoth\n",
    "%env THOTH_CEPH_BUCKET_PREFIX  data/thoth\n",
    "%env THOTH_S3_ENDPOINT_URL     https://s3.upshift.redhat.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:23:41.213146Z",
     "start_time": "2019-08-19T11:23:41.096235Z"
    }
   },
   "outputs": [],
   "source": [
    "inspection_store = InspectionResultsStore(region=\"eu-central-1\")\n",
    "inspection_store.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:24:31.607690Z",
     "start_time": "2019-08-19T11:23:41.922016Z"
    }
   },
   "outputs": [],
   "source": [
    "all_document_ids = inspection_store.get_document_listing()\n",
    "\n",
    "list_ids = [str(cid) for cid in all_document_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:42:24.105535Z",
     "start_time": "2019-08-20T10:42:24.070440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2396 inspection runs!: [('005k-test-new', 296), ('01k-test-new', 299), ('05k-test-new', 300), ('2k-test-new', 300), ('4k-test-new', 298), ('8k-test-new', 298), ('16k-test-new', 305), ('20k-test-new', 300)] respectively\n"
     ]
    }
   ],
   "source": [
    "identifier_inspection = [\n",
    "    \"005k-test-new\",\n",
    "    \"01k-test-new\",\n",
    "    \"05k-test-new\",\n",
    "    \"2k-test-new\",\n",
    "    \"4k-test-new\",\n",
    "    \"8k-test-new\",\n",
    "    \"16k-test-new\",\n",
    "    \"20k-test-new\"\n",
    "]\n",
    "list_ids_filtered = filter_inspection_list(list_ids, identifier_inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:42:37.082886Z",
     "start_time": "2019-08-19T11:24:31.647927Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspection_results = {}\n",
    "tot = sum([len(r) for r in filtered_list_ids.values()])\n",
    "n = 1\n",
    "for identifier in identifier_inspection:\n",
    "    inspection_results[identifier] = []\n",
    "\n",
    "    for ids in filtered_list_ids[identifier]:\n",
    "        document = inspection_store.retrieve_document(ids)\n",
    "        # pop build logs to save some memory (not necessary for now)\n",
    "        document[\"build_log\"] = None\n",
    "        print(f\"{n}/{tot}\")\n",
    "        inspection_results[identifier].append(document)\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:43:45.236381Z",
     "start_time": "2019-08-19T11:42:37.090449Z"
    }
   },
   "outputs": [],
   "source": [
    "df_total = {}\n",
    "\n",
    "for identifier, inspection_results_list in inspection_results.items():\n",
    "    \n",
    "    df = inspection.process_inspection_results(\n",
    "        inspection_results_list,\n",
    "        exclude=[\"build_log\", \"created\", \"inspection_id\"],\n",
    "        apply=[(\"created|started_at|finished_at\", pd.to_datetime)],\n",
    "        drop=False\n",
    "    )\n",
    "    \n",
    "    df_total[identifier] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:43:45.438703Z",
     "start_time": "2019-08-19T11:43:45.238353Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total = {}\n",
    "for identifier, dataframe in df_total.items():\n",
    "    df_duration = inspection.create_duration_dataframe(dataframe)\n",
    "    df_duration_total[identifier] = df_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:43:45.453003Z",
     "start_time": "2019-08-19T11:43:45.440185Z"
    }
   },
   "outputs": [],
   "source": [
    "for identifier, df_duration in df_duration_total.items():\n",
    "    df_total[identifier][\"job_duration\"] = df_duration[\"job_duration\"]\n",
    "    df_total[identifier][\"build_duration\"] = df_duration[\"build_duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:02:17.702470Z",
     "start_time": "2019-08-19T14:02:17.699578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect all reports and provide results\n",
    "tot_reports = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 0.05k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T08:36:04.092244Z",
     "start_time": "2019-08-20T08:36:03.661675Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"005k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T11:53:51.894600Z",
     "start_time": "2019-08-19T11:53:51.846283Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"005k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:02:21.339768Z",
     "start_time": "2019-08-19T14:02:20.953423Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_reports[\"005k-test-new\"] = create_report(df_total[\"005k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 0.1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:29.133175Z",
     "start_time": "2019-08-09T09:22:28.472649Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"01k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:24:03.626310Z",
     "start_time": "2019-08-09T09:24:03.582204Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"01k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:32.213860Z",
     "start_time": "2019-08-19T14:04:31.834655Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tot_reports[\"01k-test-new\"] = create_report(df_total[\"01k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 0.5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:33.224280Z",
     "start_time": "2019-08-09T09:22:32.980684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"05k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:24:01.480436Z",
     "start_time": "2019-08-09T09:24:01.445745Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"05k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:35.174685Z",
     "start_time": "2019-08-19T14:04:34.786212Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"05k-test-new\"] = create_report(df_total[\"05k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:30:47.197334Z",
     "start_time": "2019-08-19T15:30:46.937485Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"2k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:07:28.074192Z",
     "start_time": "2019-08-19T15:07:28.006381Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"2k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:41:14.655651Z",
     "start_time": "2019-08-20T10:41:14.263435Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 'job_log__hwinfo__platform__architecture' dtype NOT understood. Dropped\n",
      "Column 'job_log__hwinfo__cpu__is_32bit' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_64bit' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Alpha' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Core2' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_EV4' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_EV5' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_EV56' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Itanium' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_PCA56' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power7' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power8' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_Power9' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_i386' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__is_i486' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__has_Altivec' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__has_f00f_bug' could NOT be used as index group. Dropped.\n",
      "Column 'job_log__hwinfo__cpu__has_fdiv_bug' could NOT be used as index group. Dropped.\n",
      "Column 'specification__python__requirements_locked__default__absl-py__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__astor__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__gast__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__grpcio__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__h5py__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__keras-applications__hashes' dtype NOT understood. Dropped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "hardware\n",
      "=========================================================================\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "hardware -> platform\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Class 1/1\n",
      "job_log__hwinfo__platform__machine : x86_64\n",
      "job_log__hwinfo__platform__platform : Linux-3.10.0-957.21.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core\n",
      "job_log__hwinfo__platform__processor : x86_64\n",
      "job_log__hwinfo__platform__release : 3.10.0-957.21.2.el7.x86_64\n",
      "job_log__hwinfo__platform__version : #1 SMP Tue May 28 09:26:43 UTC 2019\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "hardware -> processor\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Class 1/1\n",
      "job_log__hwinfo__cpu__is_AMD : False\n",
      "job_log__hwinfo__cpu__is_AMD64 : False\n",
      "job_log__hwinfo__cpu__is_Athlon64 : False\n",
      "job_log__hwinfo__cpu__is_AthlonHX : False\n",
      "job_log__hwinfo__cpu__is_AthlonK6 : False\n",
      "job_log__hwinfo__cpu__is_AthlonK6_2 : False\n",
      "job_log__hwinfo__cpu__is_AthlonK6_3 : False\n",
      "job_log__hwinfo__cpu__is_AthlonK7 : False\n",
      "job_log__hwinfo__cpu__is_AthlonMP : False\n",
      "job_log__hwinfo__cpu__is_Celeron : False\n",
      "job_log__hwinfo__cpu__is_Hammer : False\n",
      "job_log__hwinfo__cpu__is_Intel : True\n",
      "job_log__hwinfo__cpu__is_Nocona : False\n",
      "job_log__hwinfo__cpu__is_Opteron : False\n",
      "job_log__hwinfo__cpu__is_Pentium : False\n",
      "job_log__hwinfo__cpu__is_PentiumII : False\n",
      "job_log__hwinfo__cpu__is_PentiumIII : False\n",
      "job_log__hwinfo__cpu__is_PentiumIV : False\n",
      "job_log__hwinfo__cpu__is_PentiumM : False\n",
      "job_log__hwinfo__cpu__is_PentiumMMX : False\n",
      "job_log__hwinfo__cpu__is_PentiumPro : False\n",
      "job_log__hwinfo__cpu__is_Prescott : False\n",
      "job_log__hwinfo__cpu__is_XEON : True\n",
      "job_log__hwinfo__cpu__is_Xeon : True\n",
      "job_log__hwinfo__cpu__is_i586 : False\n",
      "job_log__hwinfo__cpu__is_i686 : True\n",
      "job_log__hwinfo__cpu__is_singleCPU : False\n",
      "job_log__hwinfo__cpu__has_3dnow : False\n",
      "job_log__hwinfo__cpu__has_3dnowext : False\n",
      "job_log__hwinfo__cpu__has_mmx : True\n",
      "job_log__hwinfo__cpu__has_sse : True\n",
      "job_log__hwinfo__cpu__has_sse2 : True\n",
      "job_log__hwinfo__cpu__has_sse3 : True\n",
      "job_log__hwinfo__cpu__has_ssse3 : True\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "hardware -> ncpus\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Class 1/1\n",
      "job_log__hwinfo__cpu__ncpus : 64\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "software_stack\n",
      "=========================================================================\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "software_stack -> index\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Class 1/1\n",
      "specification__python__requirements__packages__tensorflow__index : pypi-org\n",
      "specification__python__requirements_locked__default__tensorflow__index : pypi-org\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "software_stack -> requirements_locked\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column 'specification__python__requirements_locked__default__keras-preprocessing__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__markdown__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__mock__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__numpy__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__protobuf__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__six__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__tensorboard__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__tensorflow-estimator__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__tensorflow__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__termcolor__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__werkzeug__hashes' dtype NOT understood. Dropped\n",
      "Column 'specification__python__requirements_locked__default__wheel__hashes' dtype NOT understood. Dropped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 1/1\n",
      "specification__python__requirements_locked__default__absl-py__version : ==0.7.1\n",
      "specification__python__requirements_locked__default__astor__version : ==0.8.0\n",
      "specification__python__requirements_locked__default__gast__version : ==0.2.2\n",
      "specification__python__requirements_locked__default__grpcio__version : ==1.22.0\n",
      "specification__python__requirements_locked__default__h5py__version : ==2.9.0\n",
      "specification__python__requirements_locked__default__keras-applications__version : ==1.0.8\n",
      "specification__python__requirements_locked__default__keras-preprocessing__version : ==1.1.0\n",
      "specification__python__requirements_locked__default__markdown__version : ==3.1.1\n",
      "specification__python__requirements_locked__default__mock__version : ==3.0.5\n",
      "specification__python__requirements_locked__default__numpy__version : ==1.17.0\n",
      "specification__python__requirements_locked__default__protobuf__version : ==3.9.1\n",
      "specification__python__requirements_locked__default__six__version : ==1.12.0\n",
      "specification__python__requirements_locked__default__tensorboard__version : ==1.13.1\n",
      "specification__python__requirements_locked__default__tensorflow-estimator__version : ==1.13.0\n",
      "specification__python__requirements_locked__default__tensorflow__index : pypi-org\n",
      "specification__python__requirements_locked__default__tensorflow__version : ==1.13.1\n",
      "specification__python__requirements_locked__default__termcolor__version : ==1.1.0\n",
      "specification__python__requirements_locked__default__werkzeug__version : ==0.15.5\n",
      "specification__python__requirements_locked__default__wheel__markers : python_version >= '3'\n",
      "specification__python__requirements_locked__default__wheel__version : ==0.33.4\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "base_image\n",
      "=========================================================================\n",
      "\n",
      "Class 1/1\n",
      "specification__python__requirements_locked__default__absl-py__version : ==0.7.1\n",
      "specification__python__requirements_locked__default__astor__version : ==0.8.0\n",
      "specification__python__requirements_locked__default__gast__version : ==0.2.2\n",
      "specification__python__requirements_locked__default__grpcio__version : ==1.22.0\n",
      "specification__python__requirements_locked__default__h5py__version : ==2.9.0\n",
      "specification__python__requirements_locked__default__keras-applications__version : ==1.0.8\n",
      "specification__python__requirements_locked__default__keras-preprocessing__version : ==1.1.0\n",
      "specification__python__requirements_locked__default__markdown__version : ==3.1.1\n",
      "specification__python__requirements_locked__default__mock__version : ==3.0.5\n",
      "specification__python__requirements_locked__default__numpy__version : ==1.17.0\n",
      "specification__python__requirements_locked__default__protobuf__version : ==3.9.1\n",
      "specification__python__requirements_locked__default__six__version : ==1.12.0\n",
      "specification__python__requirements_locked__default__tensorboard__version : ==1.13.1\n",
      "specification__python__requirements_locked__default__tensorflow-estimator__version : ==1.13.0\n",
      "specification__python__requirements_locked__default__tensorflow__index : pypi-org\n",
      "specification__python__requirements_locked__default__tensorflow__version : ==1.13.1\n",
      "specification__python__requirements_locked__default__termcolor__version : ==1.1.0\n",
      "specification__python__requirements_locked__default__werkzeug__version : ==0.15.5\n",
      "specification__python__requirements_locked__default__wheel__markers : python_version >= '3'\n",
      "specification__python__requirements_locked__default__wheel__version : ==0.33.4\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "pi\n",
      "=========================================================================\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "pi -> script\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Class 1/1\n",
      "job_log__script_sha256 : 48a8f416f3b67130e5848f92bd6a1a0914d75498f24f1034d1c2796c33819c95\n",
      "specification__script : https://raw.githubusercontent.com/pacospace/performance/2k-test-new/tensorflow/matmul.py\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "pi -> parameters\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Class 1/1\n",
      "job_log__stdout__name : PiMatmul\n",
      "job_log__stdout__@parameters__device : cpu\n",
      "job_log__stdout__@parameters__dtype : float32\n",
      "job_log__stdout__@parameters__matrix_size : 512\n",
      "job_log__stdout__@parameters__reps : 2000\n",
      "Number of rows (jobs) is: 300\n",
      "\n",
      "=========================================================================\n",
      "requests\n",
      "=========================================================================\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "requests -> build\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'build'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-453-f0b8a1184fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtot_reports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2k-test-new\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2k-test-new\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-450-fac148b41257>\u001b[0m in \u001b[0;36mcreate_report\u001b[0;34m(df_inspection_batch)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 sub_feature_result = inspection.query_inspection_dataframe(\n\u001b[1;32m    265\u001b[0m                     \u001b[0mdf_inspection_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                     \u001b[0mgroupby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_INSPECTION_JSON_DF_KEYS_FEATURES_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                     exclude=\"node\")\n\u001b[1;32m    268\u001b[0m                 \u001b[0mreport_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_feature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_feature_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'build'"
     ]
    }
   ],
   "source": [
    "tot_reports[\"2k-test-new\"] = create_report(df_total[\"2k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 4k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:37.098480Z",
     "start_time": "2019-08-09T09:22:36.860012Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"4k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:23:56.822557Z",
     "start_time": "2019-08-09T09:23:56.785864Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"4k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:42.414525Z",
     "start_time": "2019-08-19T14:04:42.003711Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"4k-test-new\"] = create_report(df_total[\"4k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:39.123494Z",
     "start_time": "2019-08-09T09:22:38.721397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"8k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T07:39:48.188945Z",
     "start_time": "2019-08-20T07:39:48.153957Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"8k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:02:51.626144Z",
     "start_time": "2019-08-19T14:02:51.253507Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"8k-test-new\"] = create_report(df_total[\"8k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:40.907329Z",
     "start_time": "2019-08-09T09:22:40.662089Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"16k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:23:52.380098Z",
     "start_time": "2019-08-09T09:23:52.330676Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"16k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:47.445879Z",
     "start_time": "2019-08-19T14:04:47.073970Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"16k-test-new\"] = create_report(df_total[\"16k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze batch with number of Repetitions: 20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:22:43.043836Z",
     "start_time": "2019-08-09T09:22:42.813923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_inspection_analysis_plots(df_duration_total, batch_identifier=\"20k-test-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T09:23:49.046652Z",
     "start_time": "2019-08-09T09:23:49.009925Z"
    }
   },
   "outputs": [],
   "source": [
    "df_duration_total[\"20k-test-new\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:04:51.578303Z",
     "start_time": "2019-08-19T14:04:51.178640Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_reports[\"20k-test-new\"] = create_report(df_total[\"20k-test-new\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results for all reports of the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:41:25.368979Z",
     "start_time": "2019-08-20T10:41:25.357297Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================\n",
      "hardware\n",
      "===============================================================================\n",
      "---------------------------------------------------------------------------\n",
      "platform\n",
      "---------------------------------------------------------------------------\n",
      "processor\n",
      "---------------------------------------------------------------------------\n",
      "ncpus\n",
      "\n",
      "===============================================================================\n",
      "software_stack\n",
      "===============================================================================\n",
      "---------------------------------------------------------------------------\n",
      "index\n",
      "---------------------------------------------------------------------------\n",
      "requirements_locked\n",
      "specification__python__requirements_locked__default__protobuf__version: 2\n",
      "\n",
      "===============================================================================\n",
      "base_image\n",
      "===============================================================================\n",
      "\n",
      "===============================================================================\n",
      "pi\n",
      "===============================================================================\n",
      "---------------------------------------------------------------------------\n",
      "script\n",
      "job_log__script_sha256: 8\n",
      "specification__script: 8\n",
      "---------------------------------------------------------------------------\n",
      "parameters\n",
      "job_log__stdout__@parameters__reps: 8\n",
      "\n",
      "===============================================================================\n",
      "requests\n",
      "===============================================================================\n",
      "---------------------------------------------------------------------------\n",
      "build\n",
      "---------------------------------------------------------------------------\n",
      "run\n",
      "\n",
      "===============================================================================\n",
      "exit_codes\n",
      "===============================================================================\n",
      "---------------------------------------------------------------------------\n",
      "build\n",
      "---------------------------------------------------------------------------\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "create_feature_summary(tot_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T10:41:26.219546Z",
     "start_time": "2019-08-20T10:41:26.198446Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "hardware\n",
      "=========================================================================\n",
      "\n",
      "=========================================================================\n",
      "software_stack\n",
      "=========================================================================\n",
      "-------------------------------------------------\n",
      "requirements_locked\n",
      "-------------------------------------------------\n",
      "\n",
      "specification__python__requirements_locked__default__protobuf__version: ==3.9.1\n",
      "Identifier: 005k-test-new\n",
      "Identifier: 01k-test-new\n",
      "Identifier: 05k-test-new\n",
      "Identifier: 2k-test-new\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "specification__python__requirements_locked__default__protobuf__version: ==3.9.0\n",
      "Identifier: 8k-test-new\n",
      "Identifier: 16k-test-new\n",
      "Identifier: 20k-test-new\n",
      "\n",
      "=========================================================================\n",
      "base_image\n",
      "=========================================================================\n",
      "\n",
      "=========================================================================\n",
      "pi\n",
      "=========================================================================\n",
      "-------------------------------------------------\n",
      "script\n",
      "-------------------------------------------------\n",
      "\n",
      "job_log__script_sha256: 48a8f416f3b67130e5848f92bd6a1a0914d75498f24f1034d1c2796c33819c95\n",
      "Identifier: 2k-test-new\n",
      "\n",
      "job_log__script_sha256: 18913dff7e372a0421fdd401531eabaa4b3bd8bcd90a153e74267f4de5bccde2\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "job_log__script_sha256: eef61427be50bcc1bb8643cd9801c813aaf08f6df6dc76eb9163bb41b6a4ecdb\n",
      "Identifier: 005k-test-new\n",
      "\n",
      "job_log__script_sha256: e06cc0f2c5c021b6706d82f6ea929e9d4bc4bac0b252ff53638ace059c57238e\n",
      "Identifier: 20k-test-new\n",
      "\n",
      "job_log__script_sha256: 79e4e4be41e369c4b41b0d97d74b620d7a42f05e4bc9d0863392c0512c1d6f1d\n",
      "Identifier: 16k-test-new\n",
      "\n",
      "job_log__script_sha256: 7fdf17c9815fad25ed9034eec7a0e331749298d595307f2bca6950bafe63c3db\n",
      "Identifier: 05k-test-new\n",
      "\n",
      "job_log__script_sha256: 7c9557eade759dd0a5593729b17fde95125288a72fe4fafd150f61d19636e6a7\n",
      "Identifier: 01k-test-new\n",
      "\n",
      "job_log__script_sha256: 421e47f26249c105626d2d53795d33b2ce8f63fde6a48a3b6b7e89a8fe380a85\n",
      "Identifier: 8k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/4k-test-new/tensorflow/matmul.py\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/thoth-station/performance/master/tensorflow/matmul.py\n",
      "Identifier: 20k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/8k-test-new/tensorflow/matmul.py\n",
      "Identifier: 8k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/2k-test-new/tensorflow/matmul.py\n",
      "Identifier: 2k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/16k-test-new/tensorflow/matmul.py\n",
      "Identifier: 16k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/005k-test-new/tensorflow/matmul.py\n",
      "Identifier: 005k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/05k-new-test/tensorflow/matmul.py\n",
      "Identifier: 05k-test-new\n",
      "\n",
      "specification__script: https://raw.githubusercontent.com/pacospace/performance/01k-new-test/tensorflow/matmul.py\n",
      "Identifier: 01k-test-new\n",
      "-------------------------------------------------\n",
      "parameters\n",
      "-------------------------------------------------\n",
      "\n",
      "job_log__stdout__@parameters__reps: 8000\n",
      "Identifier: 8k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 4000\n",
      "Identifier: 4k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 16000\n",
      "Identifier: 16k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 20000\n",
      "Identifier: 20k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 100\n",
      "Identifier: 01k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 2000\n",
      "Identifier: 2k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 50\n",
      "Identifier: 005k-test-new\n",
      "\n",
      "job_log__stdout__@parameters__reps: 500\n",
      "Identifier: 05k-test-new\n",
      "\n",
      "=========================================================================\n",
      "requests\n",
      "=========================================================================\n",
      "\n",
      "=========================================================================\n",
      "exit_codes\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "create_feature_summary(tot_reports, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:30:37.198742Z",
     "start_time": "2019-08-19T15:30:37.139370Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_parameter = {\n",
    "    \"job_duration\": \"job_duration\",\n",
    "    \"build_duration\": \"build_duration\",\n",
    "    \"created\": \"created\",\n",
    "    \"status__job__finished_at\": \"job_finished\",\n",
    "    \"job_log__stdout__@result__elapsed\": \"elapsed\",\n",
    "    \"job_log__stdout__@result__rate\": \"rate\",\n",
    "    \"job_log__usage__ru_utime\": \"utime\",\n",
    "    \"job_log__usage__ru_stime\": \"stime\",\n",
    "    \"job_log__usage__ru_nvcsw\": \"nvcsw\",\n",
    "    \"job_log__usage__ru_nivcsw\": \"nivcsw\"\n",
    "}\n",
    "dftotal = pd.DataFrame()\n",
    "parameters = []\n",
    "\n",
    "for key, parameter in mapping_parameter.items():\n",
    "    for identifier in identifier_inspection:\n",
    "        parameters.append(parameter)\n",
    "        dftotal[parameter + \"_\" + str(identifier.split(\"-\")[0])] = df_total[identifier][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:30:38.136583Z",
     "start_time": "2019-08-19T15:30:37.958325Z"
    }
   },
   "outputs": [],
   "source": [
    "dftotal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:30:34.169521Z",
     "start_time": "2019-08-19T15:30:34.159895Z"
    }
   },
   "outputs": [],
   "source": [
    "batches = {}\n",
    "\n",
    "for parameter in parameters:\n",
    "    batches[parameter] = create_batches_filter(\n",
    "        parameter=parameter,\n",
    "        inspection_batch_names=identifier_inspection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms of the batches for job_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:29:56.184711Z",
     "start_time": "2019-08-19T15:29:56.045634Z"
    }
   },
   "outputs": [],
   "source": [
    "dftotal[batches[\"job_duration\"]].iplot(kind=\"histogram\", bins=15, theme=\"white\", title=\"Job duration distribution per batch\",\n",
    "         xTitle='Inspection Time [s]', yTitle='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the job_duration batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:28:29.503481Z",
     "start_time": "2019-08-19T15:28:29.356598Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"job_duration\"], y_label=\"Time [s]\", title_box=\"Box plots job duration per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the elapsed batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:39:53.939965Z",
     "start_time": "2019-08-19T15:39:53.795816Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"elapsed\"], y_label=\"Elapsed [ms]\", title_box=\"Box plots elapsed time per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the rate batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:04.784095Z",
     "start_time": "2019-08-19T14:41:04.669737Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"rate\"], y_label=\"Rate [GFLOPS]\",title_box=\"Box plots rate per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the utime batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:08.652080Z",
     "start_time": "2019-08-19T14:41:08.502758Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"utime\"], y_label=\"Time [s]\", title_box=\"Box plots utime per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the stime batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:11.930253Z",
     "start_time": "2019-08-19T14:41:11.816945Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"stime\"], y_label=\"Time [s]\", title_box=\"Box plots stime per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the nvcsw batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:14.920063Z",
     "start_time": "2019-08-19T14:41:14.815936Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"nvcsw\"], y_label=\"Context Switches []\", title_box=\"Box plots nvcsw per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot of the nivcsw batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:41:18.838298Z",
     "start_time": "2019-08-19T14:41:18.729925Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_box_plot(dftotal, batches[\"nivcsw\"], y_label=\"Context Switches []\", title_box=\"Box plots nivcsw per batch\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T14:09:40.608065Z",
     "start_time": "2019-08-06T14:09:40.605168Z"
    }
   },
   "source": [
    "# Interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T09:12:01.663331Z",
     "start_time": "2019-08-20T09:12:01.556441Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping_parameter = {\n",
    "    \"job_duration\": \"job_duration\",\n",
    "    \"job_log__stdout__@result__elapsed\": \"elapsed\",\n",
    "    \"job_log__stdout__@result__rate\": \"rate\",\n",
    "    \"job_log__usage__ru_utime\": \"utime\",\n",
    "    \"job_log__usage__ru_stime\": \"stime\",\n",
    "    \"job_log__usage__ru_nvcsw\": \"nvcsw\",\n",
    "    \"job_log__usage__ru_nivcsw\": \"nivcsw\"\n",
    "}   \n",
    "\n",
    "dftotal_statistics = {}\n",
    "for parameter, key in mapping_parameter.items():\n",
    "    dftotal_statistics[key] = evaluate_statistics_per_parameter_per_batch(dict_of_df_batches=df_total, parameter=parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation for `job_duration` and `elapsed_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T09:12:05.427276Z",
     "start_time": "2019-08-20T09:12:05.164064Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"job_duration\", \"elapsed\"]\n",
    "colour = [\"g\", \"b\"]\n",
    "quantity = \"std\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel= \"Time [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:14:36.195437Z",
     "start_time": "2019-08-19T15:14:35.973808Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"elapsed\"]\n",
    "colour = [\"b\"]\n",
    "quantity = \"std\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel= \"Time [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:18:46.520430Z",
     "start_time": "2019-08-19T15:18:46.291118Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"job_duration\", \"elapsed\"]\n",
    "colour = [\"g\", \"b\"]\n",
    "quantity = \"std_error\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel= \"Time [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:18:58.890287Z",
     "start_time": "2019-08-19T15:18:58.662000Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"elapsed\"]\n",
    "colour = [\"b\"]\n",
    "quantity = \"std_error\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel= \"Time [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:08:28.258977Z",
     "start_time": "2019-08-19T15:08:28.026985Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters_selected = [\"job_duration\", \"elapsed\", \"rate\"]\n",
    "colour = [\"g\", \"b\", \"r\"]\n",
    "quantity = \"cv\"\n",
    "\n",
    "plot_batches_statistics_interpolated_different_parameters(parameters_selected=parameters_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantity=quantity,\n",
    "                                    title_ylabel=\"CV [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plots interpolated for `job_duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T14:29:25.142063Z",
     "start_time": "2019-08-19T14:29:24.883466Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameter_selected = \"job_duration\"\n",
    "colour = [\"g\", \"b\", \"b\", \"r\", \"y\", \"k\"]\n",
    "quantities = [\"median\", \"q1\", \"q3\", \"max\", \"min\", \"iqr\"]\n",
    "plot_batches_statistics_interpolated_single_parameter(parameter_selected=parameter_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantities=quantities,\n",
    "                                    title_ylabel= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plots interpolated for `elapsed_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:07:05.128066Z",
     "start_time": "2019-08-19T15:07:04.879406Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameter_selected = \"elapsed\"\n",
    "colour = [\"g\", \"b\", \"b\", \"r\", \"y\", \"k\"]\n",
    "quantities = [\"median\", \"q1\", \"q3\", \"max\", \"min\", \"iqr\"]\n",
    "plot_batches_statistics_interpolated_single_parameter(parameter_selected=parameter_selected,\n",
    "                                    colour_list=colour,\n",
    "                                    quantities=quantities,\n",
    "                                    title_ylabel= \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between `ru_utime` and `ru_nivcsw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T08:55:28.297989Z",
     "start_time": "2019-08-20T08:55:28.126965Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"005k\",\n",
    "    \"01k\",\n",
    "    \"05k\",\n",
    "    \"2k\",\n",
    "    \"4k\",\n",
    "    \"8k\",\n",
    "    \"16k\",\n",
    "    \"20k\"\n",
    "], title_scatter=\"Scatter plot different batches for utime and nivcsw\", x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:03:22.410034Z",
     "start_time": "2019-08-19T15:03:22.305733Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"005k\",\n",
    "    \"01k\",\n",
    "    \"05k\",\n",
    "], x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:04:28.194134Z",
     "start_time": "2019-08-19T15:04:28.076605Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"2k\",\n",
    "    \"4k\",\n",
    "    \"8k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:03:35.750349Z",
     "start_time": "2019-08-19T15:03:35.644713Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nivcsw\"], list_batches=[\n",
    "    \"8k\",\n",
    "    \"16k\",\n",
    "    \"20k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nivcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between `ru_utime` and `ru_nvcsw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:01:17.136012Z",
     "start_time": "2019-08-19T15:01:16.982122Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nvcsw\"], list_batches=[\n",
    "    \"005k\",\n",
    "    \"01k\",\n",
    "    \"05k\",\n",
    "    \"2k\",\n",
    "    \"4k\",\n",
    "    \"8k\",\n",
    "    \"16k\",\n",
    "    \"20k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nvcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:03:00.557113Z",
     "start_time": "2019-08-19T15:03:00.242003Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nvcsw\"], list_batches=[\n",
    "    \"005k\",\n",
    "    \"01k\",\n",
    "    \"05k\",\n",
    "], x_label=\"utime [s]\", y_label=\"nvcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:04:05.814652Z",
     "start_time": "2019-08-19T15:04:05.713763Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nvcsw\"], list_batches=[\n",
    "    \"2k\",\n",
    "    \"4k\",\n",
    "], x_label=\"utime [s]\", y_label=\"nvcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T15:02:33.975887Z",
     "start_time": "2019-08-19T15:02:33.868132Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = create_scatter_plots_for_multiple_batches(dftotal, [\"utime\", \"nvcsw\"], list_batches=[\n",
    "    \"8k\",\n",
    "    \"16k\",\n",
    "    \"20k\"\n",
    "], x_label=\"utime [s]\", y_label=\"nvcsw\")\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:39.306997Z",
     "start_time": "2019-08-19T13:58:39.301649Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_plot(data: pd.DataFrame,\n",
    "               x_axis_columns: str,\n",
    "               y_axis_columns: str,\n",
    "               title_plot: str = \"Box plot\",\n",
    "               x_label: str = \"\",\n",
    "               y_label: str = \"Variable [Measurement Unit]\"):\n",
    "    \"\"\"Create plot using two columns of the DataFrame.\"\"\"\n",
    "    figure = py.iplot(\n",
    "    {\n",
    "        'data': [\n",
    "            {\n",
    "                'x': df_tot_time[x_axis_columns],\n",
    "                'y': df_tot_time[y_axis_columns],\n",
    "                'mode': 'lines+markers',\n",
    "            } \n",
    "        ],\n",
    "        'layout': {\n",
    "            'xaxis': {'title': x_label},\n",
    "            'yaxis': {'title': y_label}\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:42.553125Z",
     "start_time": "2019-08-19T13:58:42.541061Z"
    }
   },
   "outputs": [],
   "source": [
    "tot_time_builds = []\n",
    "tot_time_jobs = []\n",
    "tot_time_sum_builds_and_jobs = []\n",
    "n_parallel = 6\n",
    "for identifier in identifier_inspection:\n",
    "    tot_time_builds.append(sum(dftotal[\"build_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel)\n",
    "    tot_time_jobs.append(sum(dftotal[\"job_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel)\n",
    "    tot_time_sum_builds_and_jobs.append(\n",
    "    (sum(dftotal[\"build_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel) + (sum(dftotal[\"job_duration\" + \"_\" + str(identifier.split(\"-\")[0])])/3600/n_parallel))\n",
    "df_tot_time = pd.DataFrame()\n",
    "df_tot_time[\"batches\"] = identifier_inspection\n",
    "df_tot_time[\"builds_time\"] = tot_time_builds\n",
    "df_tot_time[\"jobs_time\"] = tot_time_jobs\n",
    "df_tot_time[\"tot_time\"] = tot_time_sum_builds_and_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection Builds Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:43.933517Z",
     "start_time": "2019-08-19T13:58:43.839571Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plot(df_tot_time, \n",
    "            x_axis_columns= \"batches\",\n",
    "            y_axis_columns= \"builds_time\",\n",
    "            title_plot=\"Time spent to evaluate all inspections builds in hours\",\n",
    "            x_label=\"Batch Identifier\", \n",
    "            y_label=\"Tot Time for builds [h]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection Jobs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:45.074656Z",
     "start_time": "2019-08-19T13:58:44.973411Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plot(df_tot_time, \n",
    "            x_axis_columns= \"batches\",\n",
    "            y_axis_columns= \"jobs_time\",\n",
    "            title_plot=\"Time spent to evaluate all inspections jobs in hours (ASSUMPTIONS ~6 in parallel)\",\n",
    "            x_label=\"Batch Identifier\", \n",
    "            y_label=\"Tot Time for jobs [h]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection builds + Jobs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T13:58:46.375646Z",
     "start_time": "2019-08-19T13:58:46.077067Z"
    }
   },
   "outputs": [],
   "source": [
    "create_plot(df_tot_time, \n",
    "            x_axis_columns= \"batches\",\n",
    "            y_axis_columns= \"tot_time\",\n",
    "            title_plot=\"Time spent to evaluate all inspections buids + jobs in hours (ASSUMPTIONS ~6 in parallel)\",\n",
    "            x_label=\"Batch Identifier\", \n",
    "            y_label=\"Tot Time for builds + jobs [h]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch has ~300 inspections jobs. During the analysis, two different software stacks have been identified [Batches comparison](#Visualize-results-for-all-reports-of-the-batches). This is slightly different from the initial requirements to have everything constant except number of repetitions. It could be necessary to repeat some batches for consistency, therefore fixing also the dependencies required by tensorflow. \n",
    "\n",
    "From statistical and error analysis we identify the best option to consider for the number of repetitions for MatMul PI that reduce the error on the results.\n",
    "This analysis is just initial and in order to assess and conclude the quality of the test, it is necessary to add other analysis, changing the software stack, the index, etc.., but fixing the number of repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Boxplot](#Boxplot-of-the-job_duration-batches) and [Interpolation](#Box-Plots-interpolated-for-job_duration) we can see that the error for `job_duration` is increasing with repetitions.\n",
    "\n",
    "Looking at the [Boxplot](#Boxplot-of-the-elapsed-batches) and [Interpolation](#Box-Plots-interpolated-for-elapsed_time) we can see that the error for the `elapsed time` for 2k reps give the lowest error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T10:06:58.145116Z",
     "start_time": "2019-08-09T10:06:58.141245Z"
    }
   },
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between [`ru_utime` and `ru_nivcsw`](#Correlation-between-ru_utime-and-ru_nivcsw) do not show possible correlations\n",
    "\n",
    "Correlation between [`ru_utime` and `ru_nvcsw`](#Correlation-between-ru_utime-and-ru_nvcsw) shows expected behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated [time](#Time-analysis) for jobs is obtained assuming `number of builds and jobs running in parallel` according to the memory required, respectively 1Gb and 4Gb, for the available space in the namespace (32Gb). This is an approximation because in practice there are also graph-sync jobs running in the same namespace, therefore using resources of the namespace that should be used by the builds and jobs. \n",
    "It's also important to consider that Build time is also affected by the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "465.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
